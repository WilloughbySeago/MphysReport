% !TeX program = lualatex
\documentclass[fleqn]{NotesClass}

\strictpagecheck

%% Packages
\usepackage{csquotes}
\usepackage{tensor}
\usepackage{ytableau}
\ytableausetup{centertableaux}

% Tikz stuff
\usepackage{tikz}
% External
\usetikzlibrary{external}
\tikzexternalize[prefix=tikz-external/]
% Other libraries
\usetikzlibrary{positioning}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{calc}

\usepackage{tikz-cd}

\RequirePackage[%
sorting=none,  % Don't sort the references, they will appear in the order they are first cited
style=numeric-comp,  % citations like [1] and citing 1, 2, and 3 gives [1-3]
giveninits=true,  % style author names as J. Doe
language=british  % Make dates dd/mm/yyyy
]{biblatex}
\addbibresource{ref.bib}
\usepackage{xurl}

% References, should be last things loaded
\usepackage[pdfauthor={Willoughby Seago},pdftitle={MPhys Report: Computational Group Theory},pdfkeywords={group theory, representation theory, birdtracks, Lie theory},pdfsubject={Lie Groups, Representation Theory}]{hyperref}  % Should be loaded second last (cleveref last)
\colorlet{hyperrefcolor}{blue!60!black}
\hypersetup{colorlinks=true, linkcolor=hyperrefcolor, urlcolor=hyperrefcolor}
\usepackage[
capitalize,
nameinlink,
noabbrev
]{cleveref} % Should be loaded last

% My packages
\usepackage{NotesBoxes}
\usepackage{NotesMaths}

\setmathfont[range={\int, \oint, \otimes, \oplus, \bigotimes, \bigoplus}]{Latin Modern Math}

% Highlight colour
\definecolor{highlight}{HTML}{710D78}
\definecolor{my blue}{HTML}{2A0D77}
\definecolor{my red}{HTML}{770D38}
\definecolor{my green}{HTML}{14770D}
\definecolor{my yellow}{HTML}{E7BB41}
\colorlet{light highlight}{highlight!30}
\colorlet{example background}{azure(web)(azuremist)!45}
\colorlet{background color}{white}

\AtBeginEnvironment{exm}{\colorlet{background color}{example background}}
\AtEndEnvironment{exm}{\colorlet{background color}{white}}

% Title page info
\title{Computational Group Theory}
\author{Willoughby Seago}
\date{\today}
\subtitle{MPhys Project Report}
\subsubtitle{Supervised by Tony Kennedy}

% Commands
% Tikz
\tikzset{wire/.style={thick}}
\tikzset{underwire/.style={line width=1mm, background color}}
\tikzset{symmetriser/.style={fill=background color, thick, rounded corners=1pt}}
\tikzset{antisymmetriser/.style={fill=black, thick, rounded corners=1pt}}
\tikzset{wire arrow/.style={wire, postaction={decorate, decoration={markings, mark=at position #1 with {\arrow{stealth}}}}}}
\tikzset{wire arrow/.default=0.5}
\tikzset{wire arrow reversed/.style={wire, postaction={decorate, decoration={markings, mark=at position #1 with {\arrowreversed{stealth}}}}}}
\tikzset{wire arrow reversed/.default=0.5}
\tikzset{over wire/.style={wire, preaction={draw, background color, line width=#1}}}
\tikzset{over wire/.default={1.5mm}}

% Text
\newcommand{\Mathematica}{\textit{Mathematica}}

% Maths
\newcommand{\identity}{1}
\newcommand{\identityMatrix}{\symbb{I}}
\newcommand{\symmetricGroup}[1][n]{\symfrak{S}_{#1}}
\DeclareMathOperator{\Mat}{Mat}
\RenewDocumentCommand{\matrices}{ o m m }{
    \IfNoValueTF{#1}{
        \Mat(#3, #2)
    }{
        \Mat(#3, #1 \times #2)
    }
}
\renewcommand{\field}{\symbb{k}}
\newcommand{\trans}{\top}
\newcommand{\hermit}{\dagger}
\newcommand{\action}{\mathbin{.}}
\ExplSyntaxOn
% Create LaTeX interface command
\NewDocumentCommand{\cycle}{ O{\,} m }{  % optional arg is separator, mandatory
    %arg is comma separated list
    (
    \willoughby_cycle:nn { #1 } { #2 }
    )
}

\clist_new:N \l_willougbhy_cycle_clist  % Create new clist variable
\cs_new_protected:Npn \willoughby_cycle:nn #1 #2 {  % create LaTeX3 function
    \clist_set:Nn \l_willougbhy_cycle_clist { #2 }  % set clist variable with
    %clist #2 passed by user
    \clist_use:Nn \l_willougbhy_cycle_clist { #1 }  % print list separated by #1
}
\ExplSyntaxOff
\DeclarePairedDelimiter{\tuple}{\langle}{\rangle}
\newcommand{\isomorphic}{\cong}
\newcommand{\projector}[1]{\symbfup{P}_{#1}}
\newcommand{\hooknumber}[1]{#1{\phantom{?}\mkern1mu\mathclap{\ooalign{\hfil ? \hfil \cr \hfil ! \hfil}}}}
\newcommand{\dual}[1]{{#1^{*}}}
\newcommand{\lorentzGroup}{\specialOrthogonal^+(1, 3)}
\newcommand{\minkowskiSpace}{\reals^{1,3}}
\DeclareMathOperator{\tr}{tr}
\renewcommand{\ve}[1]{e_{#1}}
\newcommand{\dualve}[1]{e^{#1}}
\newcommand{\minkowskiMetric}{\eta}


\includeonly{}

\begin{document}
    \frontmatter
    \titlepage
    \maketitle
    \tableofcontents
    % \listoffigures
    % \listoftables
    \mainmatter
    
    \chapter{Introduction}
    Tensors appear in many calculations in physics, from position vectors and the moment of inertia in classical mechanics, to four vectors and Lorentz transformations in special relativity, from state vectors and operators in quantum mechanics to the metric and Riemann tensors in general relativity.
    This wide spread use makes the ability to simplify and manipulate tensor expressions an essential skill for physicists.
    Much of the work in simplifying a tensor expression comes down to recognising certain symmetries of the system and exploiting these symmetries to simplify the expression.
    To do so we need a definition of a tensor, a definition of a symmetry, and a way to combine the two in order to simplify an expression.
    These definitions are the focus of the first part of this report, and the resulting methods of simplification are the focus of the second part.
    
    Throughout this project I have been working to simultaneously understand the mathematics behind tensors and to write code which implements the procedures which come out of this mathematics for simplification of tensor expressions.
    This report should lead the reader through the relevant mathematics and occasionally highlight relevant parts of the code\footnote{the code can be found on github: \url{https://github.com/WilloughbySeago/MPhysProjectCode}}.
    This code, mostly written in \Mathematica{}, has also been used to perform many of the calculations found in examples in this report.
    Before we jump straight into the maths we will give a brief overview of the key ideas introducing only a minimal amount of mathematics.
    
    \section{Overview}\label{sec:overview}
    A tensor is something which transforms like a tensor.
    This famously unhelpful definition can be made rigorous using group theory and representation theory.
    Group theory is broadly the study of symmetry, and can be used to simplify many problems down to basic algebraic manipulation.
    Representation theory allows us to further simplify this algebra to matrix manipulation, which can then be performed on a computer.
    
    One of the most powerful tools available for simplifying expressions with tensors is to exploit symmetries which these tensors posses.
    Often this comes in the form of the simple, yet surprisingly powerful, fact that the product of something symmetric with something antisymmetric must vanish.
    This can be demonstrated with a simple argument.
    Suppose \(S, A \colon \naturals \times \naturals \to \reals\) are a symmetric antisymmetric function of natural numbers respectively.
    That is \(S(n, m) = S(m, n)\) and \(A(n, m) = -A(m, n)\).
    Then using these properties, and renaming the bound variables \(n\) and \(m\), we get the result
    \begin{alignat}{3}
        \sum_{\mathclap{n, m \in \naturals}} S(n, m)\mkern1muA(n, m) &= \sum_{\mathclap{n, m \in \naturals}} S(m, n)\mkern1muA(n, m)\\
        &= -\sum_{\mathclap{n, m \in \naturals}} S(m, n)\mkern1muA(m, n)\\
        &\overset{\mathclap{n \leftrightarrow m}}{=} \mkern10mu -\sum_{\mathclap{n, m \in \naturals}} S(n, m)\mkern1muA(n, m)
    \end{alignat}
    for all \(n, m \in \naturals\).
    Since only zero has the property of being equal to its negative we conclude
    \begin{equation}
        \sum_{\mathclap{n,m\in\naturals}} S(n, m)\mkern1mu A(n, m) = 0.
    \end{equation}
    This generalises to functions of arbitrarily many variables, whenever a function is symmetric in one pair of variables and another is antisymmetric in that same pair of variables their product vanishes identically.
    This also generalises to functions of continuous variables, replacing the sum with an integral.
    This will be the basis for many of the observations we make in this report.
    
    This result is probably familiar from expressions such as \(\delta_{ij}\varepsilon^{ijk} = 0\), where we employ the Einstein summation convention, as we shall do throughout this report.
    % possible cut
    Recall that the Kronecker delta, \(\delta^{ij}\), is symmetric, \(\delta_{ij} = \delta_{ji}\), whereas the Levi--Civita symbol, \(\varepsilon^{ijk}\), is completely antisymmetric, that is it is antisymmetric in any pair of indices, so \(\varepsilon^{ijk} = -\varepsilon^{jik} = -\varepsilon^{ikj} = -\varepsilon^{kij} = \varepsilon^{kij} = \varepsilon^{jki}\).
    % end possible cut
    
    Another example which comes up in QED is the field strength tensor, \(F^{\mu\nu} \coloneqq \partial^\mu A^\nu - \partial^\nu A^\mu\), where \(A^\mu\) is the four-potential.
    As can be seen from the definition \(F^{\mu\nu}\) is antisymmetric, \(F^{\mu\nu} = -F^{\nu\mu}\).
    We can exploit this to simplify the product \(F^{\mu\nu}F_{\mu\nu}\), which occurs frequently in QED, being the term in the Lagrangian responsible for the propagation of photons.
    Since \(F_{\mu\nu}\) is antisymmetric we are free to replace \(F^{\mu\nu}\) with any tensor whose antisymmetric part is \(F^{\mu\nu}\), since in this product the symmetric part will always vanish.
    Thus, we can replace \(F^{\mu\nu}\) with \(2\partial^\mu A^\nu\), and then we have
    \begin{equation}
        F^{\mu\nu}F_{\mu\nu} = 2(\partial^\mu A^\nu)F_{\mu\nu}.
    \end{equation}
    This halves the number of terms appearing when we expand \(F_{\mu\nu}\), simplifying many calculations in QED.
    
    The question then is how do we deal with objects with more complex symmetries?
    Tensors which aren't just totally symmetric or totally antisymmetric, but symmetric in some indices, antisymmetric in others, and possibly with some indices which don't take part in any such symmetry.
    An example of such a tensor is the Riemann tensor appearing in general relativity, characterising the curvature of spacetime.
    The Riemann tensor, \(R_{\mu\nu\rho\sigma}\), has the following symmetries:
    \begin{itemize}
        \item antisymmetric in the first two indices: \(R_{\mu\nu\rho\sigma} = -R_{\nu\mu\rho\sigma}\)
        \item antisymmetric in the second two indices: \(R_{\mu\nu\rho\sigma} = -R_{\mu\nu\sigma\rho}\)
        \item symmetric upon exchange of the first pair of indices with the second pair of indices: \(R_{\mu\nu\rho\sigma} = R_{\rho\sigma\mu\nu}\).
    \end{itemize}
    
    This motivates much of the work in the following report.
    First, we need a general definition of a tensor to understand the sort of objects with which we are working.
    This leads to group theory and representation theory.
    Then should be to find a way to classify these symmetries.
    This will lead to the idea of the symmetric group and Young diagrams and Young tableaux.
    Once we have these we will look for a way to produce tensors with these symmetries.
    This leads to the idea of Young projectors.
    Finally we look at how these ideas can be applied to simplify tensor expressions.
    
    \section{Preliminary Matters}
    The Einstein summation convention will be in place throughout this report, whenever an index is repeated twice it is to be summed over, unless explicitly told otherwise.
    Generally repeated indices must be one up and one down, although there are certain cases where this requirement can be relaxed.
    
    Greek letters are used for Lorentz indices, for example, \(\mu\) and \(\nu\).
    These run from 0 to 3, with 0 being the time coordinate and 1, 2, and 3 the three spatial coordinates.
    In this context Latin letters, such as \(i\) and \(j\), are used to denote explicitly the spatial components.
    
    In more general settings Latin letters are used as indices.
    The values these take on run from 1 to the dimension of the space, which is usually evident from context.
    
    In particular for a Lie group indices are taken from the start of the alphabet, using \(a\) and \(b\), and so on.
    
    We use the metric signature \(({+}{-}{-}{-})\) throughout, so the Minkowski metric and its inverse both have the matrix form \(\minkowskiMetric = \diag(1, -1, -1, -1)\).
    
    Throughout this report we shall make reference to the algebraic objects known as rings and fields in an attempt to make things as general as possible.
    If the reader is not familiar with these concepts then they may simply replace rings with the integers, \(\integers\), and fields with either the real numbers, \(\reals\), or complex numbers, \(\complex\).
    
    It is assumed that the reader is familiar with basic linear algebra, such as vectors and matrices.
    A few necessary concepts which appear less often in physics are recapped in \cref{app:linear algebra}
    
    \chapter{Tensors}
    We start by looking at the definition of a tensor.
    This definition can be neatly summarised as \enquote{a tensor is something which transforms like a tensor}.
    However, in doing so we deliberately avoid defining how a tensor transforms.
    Often it is enough to simply define how a specific type of tensor transforms.
    For example, in classical mechanics most of the tensors we are interested in are Cartesian tensors, these are tensors which transform under a rotation using a rotation matrix, although even here we aren't being explicit about how this rotation matrix is used.
    
    To define the transformation of a tensor in the most general way possible we need to be able to reason about general transformations, this leads to the notion of a group, a collection of symmetries with a way of combining two symmetries.
    We then need to define how an abstract group corresponds to a transformation of a vector space.
    This leads to the idea of a representation.
    We then use representations to define how a tensor transforms, and hence what a tensor is.
    
    \section{Groups}
    Groups capture and abstract the idea of a symmetry.
    Intuitively a symmetry is something we can do to a system which leaves the system unchanged, or \defineindex{invariant}, under that symmetry.
    We can abstract the notion of a symmetry through four requirements.
    Given some collection of symmetries there must be a way to combine them, some way to do nothing to the system, some way to undo any of the symmetries, and the final requirement is more technical, but can be neatly summarised as it doesn't matter how we use brackets when writing down these symmetry compositions.
    This leads to the following definition.
    
    \begin{dfn}{Group}{}
        A \defineindex{group}, \((G, \cdot)\), is a set, \(G\), and a binary operation, \(\cdot \colon G \times G \to G\) such that the following axioms are satisfied \cite{riley-hobson-bence}:
        \begin{description}
            \item[Identity]\index{identity} there exists some distinguished element, \(\identity \in G\), such that for all \(x \in G\) we have \(\identity \cdot x = x \cdot \identity = x\);
            \item[Inverse]\index{inverse} for all \(x \in G\) there exists some \(x^{-1} \in G\) such that \(x \cdot x^{-1} = x^{-1} \cdot x = \identity\);
            \item[Associativity]\index{associativity} for all \(x, y, z \in G\) we have \((x \cdot y) \cdot z = x \cdot (y \cdot z)\).
        \end{description}
    \end{dfn}
    
    We follow the common abuse of terminology and refer to \(G\) alone as the group with the operation left implicit.
    We will also write most group operations as juxtaposition, writing \(xy\) for \(x \cdot y\).
    
    The prototype for a group is the \defineindex{symmetric group} on \(n\) objects, \(\symmetricGroup\) \cite{james-rep-symmetric-group}.
    This is defined as the set
    \begin{equation}
        \symmetricGroup \coloneqq \{ \sigma \colon \{1, \dotsc, n\} \to \{1, \dotsc, n\} \mid \sigma \text{ is a bijection} \}
    \end{equation}
    with function composition as the group operation.
    We will use cycle notation for elements of \(\symmetricGroup\), where a cycle sends each element to the next in the list and the last element in the list to the first.
    For example, \(\cycle{1,3,4}\) sends \(1\) to \(3\), \(3\) to \(4\), and \(4\) to \(1\).
    In this notation the identity is the empty cycle, \(\cycle{}\).
    
    Given two groups, \(G\) and \(H\), we can form a new group, called the \defineindex{direct product} \(G \otimes W\), whose elements are pairs \((g, h) \in G \times H\), that is \(g \in G\) and \(h \in H\), with the group operation \((g, h)(g', h') = (gg', hh')\) for \(g, g' \in G\) and \(h, h' \in H\).
    
    Another important family of groups are various collections of matrices with matrix multiplication as the group operation.
    In this case the group identity is the identity matrix of  the appropriate dimension, \(\identityMatrix\).
    Let \(\matrices{n}{R}\) denote the set of \(n \times n\) matrices with entries in a ring \(R\).
    The following are all groups under matrix multiplication \cite{allanach}:
    \begin{itemize}
        \item \defineindex{general linear group} \(\generalLinear(n, \field) \coloneqq \{M \in \matrices{n}{R} \mid M \text{ is invertible} \}\);
        \item \defineindex{special linear group} \(\specialLinear(n, \field) \coloneqq \{M \in \generalLinear(n, R) \mid \det M = 1\}\);
        \item \defineindex{orthogonal group} \(\orthogonal(n) \coloneqq \{O \in \matrices{n}{\reals} \mid O^\trans O = \identityMatrix \}\);
        \item \defineindex{special orthogonal group} \(\specialOrthogonal(n) \coloneqq \{O \in \orthogonal(n) \mid \det O = 1\}\);
        \item \defineindex{unitary group} \(\unitary(n) \coloneqq \{U \in \matrices{n}{\complex} \mid U^\hermit U = \identityMatrix \}\);
        \item \defineindex{special unitary group} \(\specialUnitary(n) \coloneqq \{U \in \unitary(n) \mid \det U = 1\}\).
        \item (proper orthochronous) \defineindex{Lorentz group} \(\specialOrthogonal^+(1, 3) \coloneqq \{\Lambda \in \Mat(\reals, 4) \mid \Lambda^{\trans}\minkowskiMetric \Lambda = \minkowskiMetric \land \det \Lambda = 1 \land \tensor{\Lambda}{^0_0} \ge 1\}\).
    \end{itemize}
    Most of the transformations we are interested in will form a Lie group like one of these examples, for example, \(\specialOrthogonal(n)\) corresponds to rotations in \(n\) dimensions and \(\specialOrthogonal^+(1, 3)\) corresponds to Lorentz transformations.
    These matrix groups are actually examples of a Lie group.
    
    \begin{dfn}{Lie Group}{}
        A \defineindex{Lie group}, \(G\), is a group which is also a manifold in a compatible way \cite{san-martin-lie-groups}.
        In particular, the product map, \(\cdot \colon G \times G \to G\), is analytic.
    \end{dfn}
    % TODO: define a Lie algebra
    
    Most of the time when considering a group we think of the symmetries it represents being applied to some object.
    Indeed, even group multiplication can be viewed as the symmetries of the group being applied to itself.
    Thinking in this way leads to the following definition in which each group element represents a symmetry that can be applied to some object.
    
    \begin{dfn}{Group Action}{}
        Let \(G\) be a group and \(X\) a set.
        A (left) \defineindex{group action} of \(G\) on \(X\) is a function \(\varphi \colon G \times X \to X\) such that \cite[713]{hassani}
        \begin{description}
            \item[Identity] for all \(x \in X\) we have \(\varphi(\identity, x) = x\),
            \item[Compatibility] for all \(g, h \in G\) and \(x \in X\) we have \(\varphi(g, \varphi(h, x)) = \varphi(gh, x)\) where \(gh\) is the product of \(g\) and \(h\) in \(G\).
        \end{description}
    \end{dfn}
    
    We usually write \(\varphi(g, x) = g \action x\), or even \(\varphi(g, x) = gx\).
    In this case the identity and compatibility laws take the form \(\identity \action x = x\) and \(g \action (h \action x) = (gh) \action x\), with \(gh\) being the product of \(g\) and \(h\) computed as elements of \(G\).
    
    The symmetric group, \(\symmetricGroup\), acts on \(n\)-tuples, \(\tuple{a_1, \dotsc, a_n}\), by permuting the elements.
    For example, \(\cycle{1,3,4} \in \symmetricGroup[5]\) acts on \(\tuple{a_1, a_2, a_3, a_4, a_5}\) by
    \begin{equation}
        \cycle{1,3,4} \action \tuple{a_1, a_2, a_3, a_4, a_5} = \tuple{a_4, a_2, a_1, a_3, a_5}.
    \end{equation}
    Note that this action is done by permuting the symbols \(a_i\), rather than by permuting the values of \(i\), which would instead give \(\tuple{a_3, a_2, a_4, a_1, a_5}\).
    
    Matrix groups, such as \(\generalLinear(n, \field)\) for a field \(\field\), have a natural action on the \(n\)-dimensional vector space \(\field^n\) by interpreting elements of \(\field^n\) as column matrices and then acting on them through matrix multiplication.
    The action of matrices on vector spaces in this form turns out to be a very useful way of thinking about a group, since matrix multiplication is simple and easy to perform on a computer.
    This insight leads to the idea of a representation, the subject of the next section.
    
    \begin{dfn}{Morphisms}{}
        Let \(G\) and \(H\) be groups.
        A \defineindex{group homomorphism} is a map \(\varphi \colon G \to H\) such that \(\varphi(gg') = \varphi(g)\varphi(g')\) for all \(g, g' \in G\) \cite[705]{hassani}.
        If \(\varphi\) is invertible then we call it an \defineindex{isomorphism}.
        If there is an isomorphism between \(G\) and \(H\) we say that \(G\) and \(H\) are \defineindex{isomorphic}, and denote this \(G \isomorphic H\).
    \end{dfn}
    
    Notice that if \(\identity_G\) and \(\identity_H\) are the identity elements of \(G\) and \(H\) respectively then we have \(\varphi(\identity_G) = \identity_H\) as well as \(\varphi(g^{-1}) = \varphi(g)^{-1}\) for all \(g \in G\).
    
    As mentioned before every group has a natural action on itself, that is a function \(G \times G \to G\), given by \(g \action h = gh\).
    In this way every group element, \(g\), defines a bijection \(\varphi_g \colon G \to G\) defined by \(\varphi_g(h) = gh\).
    The collection of these bijections, along with function composition, is isomorphic to the group itself, and is a subgroup of some symmetric group.
    This is Cayley's theorem, and highlights the importance of the symmetric group.
    % TODO: Find a citation
    
    There are often times when it makes sense to combine the structure of a group with the structure of a vector space, the ability to add elements and scale by some scalar.
    This leads to the following definition.
    
    \begin{dfn}{Group Algebra}{}\index{group algebra}
        Let \(G\) be a group and \(R\) a ring.
        The group ring, \(R[G]\), is the set of formal sums
        \begin{equation}
            \sum_{g \in G} r_g g
        \end{equation}
        where \(r_g \in R\) is zero for all but a finite number of elements \(g\).
        This set of formal sums is a ring with addition defined as
        \begin{equation}
            \sum_{g \in G} r_g g + \sum_{g \in G} s_g g \coloneqq \sum_{g\in G}(r_g + s_g) g
        \end{equation}
        and multiplication defined as
        \begin{equation}
            \left( \sum_{g \in G} r_g g \right) \left( \sum_{h \in G} s_h h \right) \coloneqq \sum_{g, h \in G}^{g} r_g s_h gh
        \end{equation}
        with the product \(r_gs_h\) computed in \(R\) and the product \(gh\) computed in \(G\).
        If \(R\) is a field then \(R[G]\) is an associative algebra (a vector space with an associative product), called the \defineindex{group algebra} \cite[740]{hassani}.
    \end{dfn}
    
    The most common case of a group algebra is the group algebra \(\complex[G]\) for some arbitrary group, \(G\).
    Elements of this take the form \(z_i g_i\) for some \(z_i \in \complex\) and \(g_i \in G\), using the Einstein summation convention.
    
    \section{Representations}
    Let \(V\) be a vector space over the field \(\field\).
    Denote by \(\generalLinear(V)\) the space of all invertible linear transformations on \(V\), that is
    \begin{equation}
        \generalLinear(V) \coloneqq \{T \colon V \to V \mid T \text{ is linear and invertible}\}.
    \end{equation}
    For finite dimensional vector spaces if we fix some basis for \(V\) then we can identify linear transformations with matrices and we find that \(\generalLinear(V) \isomorphic \generalLinear(\dim V, \field)\).
    
    The general linear group, \(\generalLinear(V)\), has a natural group action on \(V\), namely, \(T \action v = T(v)\) for a linear transformation \(T \in \generalLinear(V)\) and a vector \(v \in V\).
    This can be extended to an arbitrary group, \(G\), by factoring this action through a group homomorphism.
    That is we can map \(G\) into \(\generalLinear(V)\) with a group homomorphism, \(\rho \colon G \to \generalLinear(V)\), turning group elements in \(g\) into linear transformations on \(V\), then act on \(V\) with these linear transformations.
    This defines a group action \(\action \colon G \times V \to V\), given by \(g \action v = \rho(g)(v)\).
    The notation \(\rho(g)(v)\) denotes evaluating \(\rho\) at \(g \in G\), returning a linear transformation \(\rho(g) \in \generalLinear(V)\), which we then evaluate at \(v\).
    The result is what we call a representation, an alternative definition is given below.
    
    \begin{dfn}{Representation}{}
        Let \(G\) be a group.
        A \defineindex{group representation}, \((\rho, V)\), is a pair consisting of a vector space, \(V\), called the representation space, and a homomorphism \(\rho \colon G \to \generalLinear(V)\) \cite[726]{hassani}.
    \end{dfn}
    
    It is common to refer to both \(\rho\), \(V\), alone, as well as the pair \((\rho, V)\) as the representation.
    The simplest example of a representation is the \defineindex{trivial representation}, \((\rho_{\text{trivial}}, V)\), which acts trivially on \(V\), that is \(\rho_{\text{trivial}}(g) = \identityMatrix\), or equivalently, \(g \action v = v\) for all \(g \in G\).
    
    \begin{exm}{Permutation Representation}{}
        Consider the symmetric group on three elements, \(\symmetricGroup[3]\).
        This has a representation on \(\reals^3\) given by identifying
        \begin{equation*}
            \rho\cycle{1,2} = 
            \begin{pmatrix}
                0 & 1 & 0\\
                1 & 0 & 0\\
                0 & 0 & 1
            \end{pmatrix}
            ,\ \rho\cycle{1,3} = 
            \begin{pmatrix}
                0 & 0 & 1\\
                0 & 1 & 0\\
                1 & 0 & 0
            \end{pmatrix}
            , \ \text{and} \  \rho\cycle{2,3} = 
            \begin{pmatrix}
                1 & 0 & 0\\
                0 & 0 & 1\\
                0 & 1 & 0
            \end{pmatrix}
            .
        \end{equation*}
        This representation acts by permuting the basis vectors \(\ve{1} = (1, 0, 0)^\trans\), \(\ve{2} = (0, 1, 0)^\trans\), and \(\ve{3} = (0, 0, 1)^\trans\), for example \(\rho\cycle{1,2} \mkern1mu \ve{1} = \ve{2}\), so we call this the \defineindex{permutation representation}.
        The representation of any other group element can be found by writing the element as a product of \define{transpositions}\index{transposition} (two element cycles).
        For example, \(\cycle{1,2,3} = \cycle{1,2}\cycle{2,3}\) and so
        \begin{multline}
            \rho\cycle{1,2,3} = \rho(\cycle{1,2} \cycle{2,3}) = \rho\cycle{1,2} \, \rho\cycle{2,3}\\
            = 
            \begin{pmatrix}
                0 & 1 & 0\\
                1 & 0 & 0\\
                0 & 0 & 1
            \end{pmatrix}
            \begin{pmatrix}
                1 & 0 & 0\\
                0 & 0 & 1\\
                0 & 1 & 0
            \end{pmatrix}
            = 
            \begin{pmatrix}
                0 & 0 & 1\\
                1 & 0 & 0\\
                0 & 1 & 0
            \end{pmatrix}
            .
        \end{multline}
    \end{exm}
    
    There are an infinite number of representations of any group, however, they are not all equally interesting.
    This is evident since given some representation, \((\rho, V)\), we can form a new representation \((\rho', W)\), where \(V\) is a subspace of \(W\), by defining \(\rho' = \rho \oplus \identityMatrix_{V^\perp}\) where \(V^{\perp}\) is the space such that \(W = V \oplus V^{\perp}\), so \(\rho'(g)\) acts as \(\rho(g)\) on the subspace \(V\) and acts trivially on the orthogonal subspace \(V^{\perp}\).
    Clearly this representation doesn't really give us any new information.
    More generally, given two representations, \((\rho_1, V_1)\) and \((\rho_2, V_2)\), we can form a representation \((\rho_1 \oplus \rho_2, V_1 \oplus V_2)\), again, we don't get any new information out of this new representation.
    For this reason we define irreducible representations, which are exactly the representations which aren't of this form.
    
    \begin{dfn}{Irreducible Representation}{}
        Let \(G\) be a group and \((\rho, V)\) a representation of \(G\).
        We say that \((\rho, V)\) is an \defineindex{irreducible representation}, or irrep, if \(V\) has no \(G\)-invariant subspaces \cite{hamermesh}.
        That is, there is no \(W \subset V\) such that \(g \action w \in W\) for all \(w \in W\).
    \end{dfn}

    \begin{dfn}{Decomposable Representation}{}
        Let \(G\) be a group and \((\rho, V)\) a representation of \(G\).
        We say that \((\rho, V)\) is a \defineindex{decomposable representation} if \(\{\rho(g)\}\) can be simultaneously block diagonalised \cite{hamermesh}.
        In other words, there exist representations \((\rho_i, V_i)\) such that \(\rho = \bigoplus_i \rho_i\) and \(V = \bigoplus_i V_i\).
    \end{dfn}
    
    For a finite group, \(G\), and a representation space over \(\reals\) or \(\complex\) all indecomposable representations are irreducible \cite{hamermesh}.
    This also the case if \(G\) is compact.
    We will assume that all indecomposable are irreducible and vice versa.
    
    Representations give us the final piece of machinery required to make \enquote{a tensor is something which transforms like a tensor} precise.
    A tensor is something which transforms under some representation of 
    \begin{dfn}{Tensor}{def:tensor}
        Let \(G\) be a group and \(V\) a vector space over a field \(\field\).
        Denote by \(\dual{V}\) the dual space to \(V\), that is the space of all linear maps \(V \to \field\).
        Fix some representation \(\rho \colon G \to \generalLinear(V)\).
        A \defineindex{tensor}, \(T \in V^{\otimes p} \otimes \dual{V}^{\otimes q}\), is an object with components \(\tensor{T}{^{a_1\dotso a_q}_{b_1 \dotso b_p}}\), which transform under the action of \(g \in G\) such that \(T' = g \action T = \rho(g)T\) has components
        \begin{equation*}
            \tensor{{T'}}{^{a_1\dotso a_q}_{b_1 \dotso b_p}} = \tensor{\rho(g)}{^{a_1}_{c_1}} \dotsm \tensor{\rho(g)}{^{a_q}_{c_q}} \tensor{\rho(g)}{_{b_1}^{d_q}} \dotsm \tensor{\rho(g)}{_{b_p}^{d_p}} \tensor{T}{^{c_1\dotso c_q}_{d_1 \dotso d_p}}
        \end{equation*}
        where we employ the Einstein summation convention and sum over repeated indices from \(1\) to \(\dim V\) \cite[18]{cvitanovic}.
    \end{dfn}
    
    We will follow the common physics abuse of terminology and refer to the components \(\tensor{T}{^{a_1\dotso a_q}_{b_1\dotso b_p}}\) as being the tensor see \cref{sec:technicalities tensor defs}.
    
    Note that what we have defined above may be more specifically called a \((p, q)\)-tensor.
    A \((p, 0)\)-tensor is also commonly referred to as a rank \(p\) contravariant tensor, or simply a rank \(p\) tensor, and a \((0, q)\)-tensor may be referred to as a rank \(q\) covariant tensor.
    
    \begin{exm}{}{}
        In classical mechanics we consider Cartesian tensors, which transform under the rotation group \(\specialOrthogonal(3)\).
        For example, if \(R \in \specialOrthogonal(3)\) is a rotation matrix then \(\vv{x} \in \reals^3\) is a vector if it has components transforming according to
        \begin{equation}
            x_i = R_{ij}x_j.
        \end{equation}
        The moment of inertia tensor, \(I\), has components \(I_{ij}\) and transforms as
        \begin{equation}
            I'_{ij} = R_{ik}R_{jl}I_{kl},
        \end{equation}
        so it is a rank 2 tensor.
        
        In relativity we consider Lorentz tensors, which transform under the Lorentz group \(\lorentzGroup\).
        For example, if \(\Lambda \in \lorentzGroup\) is a Lorentz transformation then \(x \in \minkowskiSpace\) is a vector if it has components transforming according to
        \begin{equation}
            x^\mu = \tensor{\Lambda}{^\mu_\nu}x^\nu.
        \end{equation}
        The energy-momentum tensor, \(T\), has components \(T^{\mu\nu}\) which transform as
        \begin{equation}
            T'^{\mu\nu} = \tensor{\Lambda}{^\mu_\rho}\tensor{\Lambda}{^\nu_\sigma} T^{\rho\sigma},
        \end{equation}
        so it is a rank 2 contravariant tensor.
    \end{exm}
    
    Given two tensors, \(R \in V^{\otimes q} \otimes \dual{V}^{\otimes p}\) and \(T \in V^{\otimes r} \otimes \dual{V}^{\otimes s}\), we can form a new tensor \(R \otimes T \in V^{\otimes(q + r)} \otimes \dual{V}^{\otimes(p + s)}\), with components given by
    \begin{equation}
        \tensor{(R \otimes T)}{^{a_1\dotso a_q b_1 \dotso b_r}_{c_1 \dotso c_p d_1 \dotso d_s}} = \tensor{R}{^{a_1\dotso a_q}_{c_1 \dotso c_p}} \tensor{T}{^{b_1 \dotso b_r}_{d_1 \dotso d_s}}.
    \end{equation}
    This operation is often used implicitly, such as writing \(k^\mu k^\nu\), and neglecting to note that this object actually lives in a different space to \(k^\mu\), namely it lives in \(V \otimes V\).
    
    % TODO: Maybe talk about raising and lowering indices? Using Killing form?
    
    \section{Birdtracks}
    \subsection{Birdtracks for Tensors}
    Equations involving multiple tensors, particularly with contractions between the tensors, can quickly become a mess of indices, and keeping track of which indices are free and which are summed can be a demanding task.
    Anyone who's worked with tensors extensively will have at some point in their calculations run out of appropriate letters to use as indices, and accidentally reusing a letter can make an entire expression completely meaningless.
    For this reason we now introduce a notation known as \defineindex{birdtracks} for expressing the components of tensors.
    
    Birdtracks are inspired by Feynman diagrams, and indeed sometimes arise explicitly as Feynman diagrams, and indeed many Feynman diagrams can be directly interpreted as birdtracks.
    This notation was first developed by Roger Penrose % TODO: citation
    who originally designed the notation for use in general relativity.
    The general idea is to represent a tensor as a vertex in a graph, with the edges of the graph, which we call wires, being the indices of the tensor.
    Two vertices are joined by an edge if that index is contracted over.
    We distinguish contravariant and covariant indices where required with arrows on the line, pointing away from the vertex for a contravariant index and towards it for a covariant index.
    Allowing only one arrow on each line ensures that we can only contract a contravariant index with a covariant index.
    
    For example, suppose we have a tensor with components \(\tensor{T}{^{abc}_{de}}\), which we wish to represent in this notation.
    We write this as
    \begin{equation}
        \tensor{T}{^{abc}_{de}} = 
        \tikzsetnextfilename{birdtracks-example-tensor}
        \begin{tikzpicture}[baseline=(T.base)]
            \node[draw, minimum width=1cm, minimum height=1.5cm] (T) {\(T\)};
            \draw[wire arrow reversed=0.425] ($(T.west) + (0, 0.6)$) -- ++ (-1, 0) node [left, font=\scriptsize] {\(a\)};
            \draw[wire arrow reversed=0.425] ($(T.west) + (0, 0.3)$) -- ++ (-1, 0) node [left, font=\scriptsize] {\(b\)};
            \draw[wire arrow reversed=0.425] (T.west) -- ++ (-1, 0) node [left, font=\scriptsize] {\(c\)};
            \draw[wire arrow=0.575] ($(T.west) + (0, -0.3)$) -- ++ (-1, 0) node [left, font=\scriptsize] {\(d\)};
            \draw[wire arrow=0.575] ($(T.west) + (0, -0.6)$) -- ++ (-1, 0) node [left, font=\scriptsize] {\(e\)};
        \end{tikzpicture}
        .
    \end{equation}
    We include the index labels only for comparison with the notation \(\tensor{T}{^{abc}_{de}}\), in general they can be dropped.
    In doing so it is important to always read the indices going anticlockwise around the tensor to get the order correct.
    Which index we start with often doesn't matter, as long as we are consistent, but when it does we may mark the starting index, or arrange the indices in such a way that it is clear where to start, here we do so by having \(a\) at the top.
    
    It is not important at what position a wire enters a node, nor is it important where the wire goes if the corresponding index is not contracted.
    This leaves us free to bend wires, and move them around as needed.
    It is only the connectivity between different tensors which we care about.
    
    The Kronecker delta is a common enough tensor that we give it its own special notation, we draw it as a wire with no node:
    \begin{equation}
        \tensor{\delta}{^a_b} = 
        \tikzsetnextfilename{birdtracks-kronecker-delta}
        \begin{tikzpicture}[baseline=(b.base)]
            \draw[wire arrow=0.575] (0, 0) node [right, font=\scriptsize] {\(a\)} -- (-1, 0) node [left, font=\scriptsize] (b) {\(b\)};
        \end{tikzpicture}
        .
    \end{equation}
    In the language of Feynman diagrams we may refer to this as a propagator.
    Indeed, many propagators, such as those of a particle with colour charge, carry a factor of \(\tensor{\delta}{^a_b}\), acting as the identity on colour space, so the colour of the particle doesn't change as it propagates.
    
    To contract tensors we join up the contracted indices.
    For example, we can write \(\tensor{T}{^{abc}_{de}}\tensor{R}{^{d}_{afc}}\) as
    \begin{equation}
        \tensor{T}{^{abc}_{de}} \tensor{R}{^{d}_{afc}} = 
        \tikzsetnextfilename{birdtracks-contraction}
        \begin{tikzpicture}[baseline=(T.base)]
            \node[draw, minimum width=1cm, minimum height=1.5cm] (T) {\(T\)};
            \draw[wire arrow=0.575] ($(T.east) + (0, 0.6)$) -- ++ (1, 0) node [right, font=\scriptsize, xshift=-0.1cm] {\(e\)};
            \draw[wire arrow=0.575] ($(T.east) + (0, 0.3)$) -- ++ (1, 0) coordinate (T2);
            \draw[wire arrow reversed=0.425] (T.east) -- ++ (1, 0) coordinate (T3);
            \draw[wire arrow reversed=0.425] ($(T.east) + (0, -0.3)$) -- ++ (1, 0) node [right, font=\scriptsize, xshift=-0.1cm] {\(b\)};
            \draw[wire arrow reversed=0.425] ($(T.east) + (0, -0.6)$) -- ++ (1, 0) coordinate (T5);
            \node[draw, minimum width=1cm, minimum height=1.5cm] (R) at (4, 0) {\(R\)};
            \draw[wire arrow=0.575] ($(R.west) + (0, 0.6)$) -- ++ (-1, 0) coordinate (R1);
            \draw[wire arrow=0.575] ($(R.west) + (0, 0.2)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.13cm] {\(f\)};
            \draw[wire arrow=0.575] ($(R.west) + (0, -0.2)$) -- ++ (-1, 0) coordinate (R3);
            \draw[wire arrow reversed=0.425] ($(R.west) + (0, -0.6)$) -- ++ (-1, 0) coordinate (R4);
            \draw[over wire, rounded corners] ($(T2) + (-0.1, 0)$) -- ++ (0.4, 0) -- ++ (0.4, -0.9) -- ($(R4) + (0.1, 0)$) node [below, font=\scriptsize, shift={(-0.2, 0.08)}] {\(d\)};
            \draw[over wire, rounded corners] ($(T3) + (-0.1, 0)$) -- ++ (0.4, 0) -- ++ (0.4, 0.6) -- ($(R1) + (0.1, 0)$) node [above, font=\scriptsize, shift={(-0.2, -0.08)}] {\(c\)};
            \draw[over wire, rounded corners] ($(T5) + (-0.1, 0)$) -- ++ (0.4, 0) -- ++ (0.4, 0.4) -- ($(R3) + (0.1, 0)$) node [above, font=\scriptsize, shift={(-0.2, -0.08)}] {\(a\)};
        \end{tikzpicture}
        .
    \end{equation}
    Again, the indices are labelled for comparison to the index notation.
    
    It is possible to contract indices on the same tensor, this is drawn as a loop.
    For example, given a rank 2 tensor \(M\) its trace is
    \begin{equation}
        \tr(M) = \tensor{M}{^a_a} = 
        \tikzsetnextfilename{birdtracks-trace}
        \begin{tikzpicture}[baseline=(M.base)]
            \node[draw] (M) {\(M\)};
            \node at (0, 0.45) {};
            \draw[wire arrow=0.54] (M.west) arc (270:90:0.2) coordinate (here) -- (M.east |- here) arc (90:-90:0.2);
        \end{tikzpicture}
        .
    \end{equation}
    A particularly common example of this is the trace of the Kronecker delta, \(\tensor{\delta}{^a_a} = n\), where \(n\) is the dimension of the vector space \(V\), recalling that \(\delta \in V \otimes \dual{V}\).
    This is then drawn as
    \begin{equation}
        \tensor{\delta}{^a_a} = 
        \tikzsetnextfilename{birdtracks-kronecker-delta-trace}
        \begin{tikzpicture}[baseline=-0.08cm]
            \draw[wire] circle [radius=0.3];
            \draw[thick, decorate, decoration={markings, mark =at position 1 with \arrow{stealth}}] (0.05, 0.3) -- ++ (0.01, 0);
            \node at (0, 0.35) {};
        \end{tikzpicture}
        = n.
    \end{equation}
    
    Given two tensors, such as \(\tensor{T}{^{abc}_{de}}\) and \(\tensor{R}{^{f}_{ghi}}\), we can form their tensor product, which has components \(\tensor{(T \otimes R)}{^{abcf}_{deghi}} = \tensor{T}{^{abc}_{de}}\tensor{R}{^f_{ghi}}\).
    Diagrammatically, this is represented by simply placing the two tensors next to each other with no indices contracted:
    \begin{equation}
        \tikzsetnextfilename{birdtracks-tensor-product}
        \begin{tikzpicture}[baseline=(T.base)]
            \node[draw, minimum width=1cm, minimum height=1.5cm] (T) {\(T\)};
            \draw[wire arrow=0.575] ($(T.west) + (0, 0.6)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(a\)};
            \draw[wire arrow=0.575] ($(T.west) + (0, 0.3)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(b\)};
            \draw[wire arrow reversed=0.425] (T.west) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(c\)};
            \draw[wire arrow reversed=0.425] ($(T.west) + (0, -0.3)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(d\)};
            \draw[wire arrow reversed=0.425] ($(T.west) + (0, -0.6)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(e\)};
            \node[draw, minimum width=1cm, minimum height=1.5cm] (R) at (2.5, 0) {\(R\)};
            \draw[wire arrow=0.575] ($(R.west) + (0, 0.6)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(f\)};
            \draw[wire arrow=0.575] ($(R.west) + (0, 0.2)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.13cm] {\(g\)};
            \draw[wire arrow=0.575] ($(R.west) + (0, -0.2)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(h\)};
            \draw[wire arrow reversed=0.425] ($(R.west) + (0, -0.6)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(i\)};
        \end{tikzpicture}
    \end{equation}
    While the tensor product is not strictly commutative it is up to isomorphism, that is there is an invertible linear map \(V \otimes W \to W \otimes V\), and this map is compatible with all of the relevant structure, and is uniquely defined.
    This means we are free to move these tensors around in the diagram, as well as the manipulation of the wires which we have been doing so far.
    
    We can express symmetries of a tensor in this notation by crossing wires to denote swapping the indices.
    For example, if \(S^{ab}\) is a symmetric tensor then we have
    \begin{equation}
        S^{ab} = 
        \tikzsetnextfilename{birdtracks-symmetric-tensor-1}
        \begin{tikzpicture}[baseline=(S.base)]
            \node[draw] (S) {\(T\)};
            \draw[wire arrow=0.575] ($(S.west) + (0, 0.15)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(a\)};
            \draw[wire arrow=0.575] ($(S.west) + (0, -0.15)$) -- ++ (-1, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(b\)};
        \end{tikzpicture}
        \mkern5mu =
        \tikzsetnextfilename{birdtracks-symmetric-tensor-2}
        \begin{tikzpicture}[baseline=(S.base)]
            \node[draw] (S) {\(S\)};
            \draw[wire arrow=0.85, rounded corners] ($(S.west) + (0, -0.15)$) -- ++ (-0.3, 0) -- ++ (-0.3, 0.3) -- ++ (-0.4, 0) node [left, font=\scriptsize, xshift=0.1cm] {\(b\)};
            \draw[wire arrow=0.85, rounded corners, over wire] ($(S.west) + (0, 0.15)$) -- ++ (-0.3, 0) -- ++ (-0.3, -0.3) -- ++ (-0.4, 0) coordinate (a) node [left, font=\scriptsize, xshift=0.1cm] {\(a\)};
        \end{tikzpicture}
        \mkern4mu = S^{ba}.
    \end{equation}
    
    We can think of the symmetry of a tensor as the action of the symmetric group on its indices.
    In general given \(V^{\otimes p} \otimes \dual{V}^{\otimes q}\), there is a natural action of \(\symmetricGroup[p] \otimes \symmetricGroup[q]\) on this space, \(\symmetricGroup[p]\) acts to permute the copies of \(V\) and \(\symmetricGroup[q]\) acts to permute the copies of \(\dual{V}\).
    In terms of the components this corresponds to permuting upper indices and permuting lower indices.
    For example, that \(S^{ab}\) is symmetric means that \(S^{ab}\) is invariant under the action of \(\cycle{1,2} \in \symmetricGroup[2]\).
    In general, a totally symmetric tensor, \(S^{a_1\dotso a_p}\), is invariant under the action of any permutation in \(\symmetricGroup[p]\).
    Likewise, a totally antisymmetric tensor, \(A^{a_1\dotso a_p}\), is invariant under any even permutation in \(\symmetricGroup[p]\) and picks up a factor of \(-1\) under any odd permutation in \(\symmetricGroup[p]\).
    
    \subsection{Birdtracks for the Symmetric Group}
    This identification of symmetries with permutations allows us to extend this notation to a notation for the symmetric group.
    We don't write any arrows, since these only tell us whether and index is contravariant or covariant, which depends on what tensor we are acting on.
    A permutation in \(\symmetricGroup\) can then be pictured as a collection of wires tracking \(n\) elements swapping around \cite[49]{cvitanovic}.
    For example, the permutation \(\cycle{1,2,4} \in \symmetricGroup[5]\) can be drawn, including labels normally left implicit, as
    \begin{equation}
        \tikzsetnextfilename{math-prelims-example-braid}
        \begin{tikzpicture}[baseline=(current bounding box)]
            \draw[wire] (0, 0.5) node [left] {5} -- (2.5, 0.5) node [right] {5};
            \draw[wire] (0, 1.5) node [left] {4} -- (2.5, 1.5) node [right] {4};
            \draw[underwire, rounded corners] (0, 1) -- (0.5, 1) -- (2, 2.5) -- (2.5, 2.5);
            \draw[wire, rounded corners] (0, 1) node [left] {3} -- (0.5, 1) -- (2, 2.5) -- (2.5, 2.5) node [right] {3};
            \draw[underwire, rounded corners] (0, 2.5) -- (0.5, 2.5) -- (1, 2) -- (2.5, 2);
            \draw[wire, rounded corners] (0, 2.5) node [left] {1} -- (0.5, 2.5) -- (1, 2) -- (2.5, 2) node [right] {1};
            \draw[underwire, rounded corners] (0, 2) -- (0.5, 2) -- (1.5, 1) -- (2.5, 1);
            \draw[wire, rounded corners] (0, 2) node [left] {2} -- (0.5, 2) -- (1.5, 1) -- (2.5, 1) node [right] {2};
        \end{tikzpicture}
        \ .
    \end{equation}
    
    In this notation two permutations can be composed by writing the diagrams \emph{in the opposite order to the product} and joining up the outputs of one to the inputs of the other.
    For example, the product \(\cycle{1,2,4} \cycle{3,4} = \cycle{1,2,4,3}\), viewed in \(\symmetricGroup[5]\), can be computed by connecting up the relevant diagrams:
    \begin{equation}
        \tikzsetnextfilename{math-prelims-example-diagram-composition}
        \begin{tikzpicture}[baseline=(current bounding box)]
            \draw[wire] (0, 0) -- (2.5, 0);
            \draw[wire] (0, 1) -- (2.5, 1);
            \draw[underwire, rounded corners] (0, 0.5) -- (0.5, 0.5) -- (2, 2) -- (2.5, 2);
            \draw[wire, rounded corners] (0, 0.5) -- (0.5, 0.5) -- (2, 2) -- (2.5, 2);
            \draw[underwire, rounded corners] (0, 2) -- (0.5, 2) -- (1, 1.5) -- (2.5, 1.5);
            \draw[wire, rounded corners] (0, 2) -- (0.5, 2) -- (1, 1.5) -- (2.5, 1.5);
            \draw[underwire, rounded corners] (0, 1.5) -- (0.5, 1.5) -- (1.5, 0.5) -- (2.5, 0.5);
            \draw[wire, rounded corners] (0, 1.5) -- (0.5, 1.5) -- (1.5, 0.5) -- (2.5, 0.5);
            \begin{scope}[xshift=3.5cm]
                \draw[wire] (0, 0) -- (1.5, 0);
                \draw[underwire, rounded corners] (0, 0.5) -- (0.5, 0.5) -- (1, 1) -- (1.5, 1);
                \draw[wire, rounded corners] (0, 0.5) -- (0.5, 0.5) -- (1, 1) -- (1.5, 1);
                \draw[wire, rounded corners] (0, 1) -- (0.5, 1) -- (1, 0.5) -- (1.5, 0.5);
                \draw[wire] (0, 1.5) -- (1.5, 1.5);
                \draw[wire] (0, 2) -- (1.5, 2);
            \end{scope}
            \node at (3, 1) {\(\circ\)};
            \node at (5.5, 1) {\(=\)};
            \begin{scope}[xshift=7.5cm]
                \draw[wire] (0, 0) -- (2.5, 0);
                \draw[wire] (0, 1) -- (2.5, 1);
                \draw[underwire, rounded corners] (0, 0.5) -- (0.5, 0.5) -- (2, 2) -- (2.5, 2);
                \draw[wire, rounded corners] (0, 0.5) -- (0.5, 0.5) -- (2, 2) -- (2.5, 2);
                \draw[underwire, rounded corners] (0, 2) -- (0.5, 2) -- (1, 1.5) -- (2.5, 1.5);
                \draw[wire, rounded corners] (0, 2) -- (0.5, 2) -- (1, 1.5) -- (2.5, 1.5);
                \draw[underwire, rounded corners] (0, 1.5) -- (0.5, 1.5) -- (1.5, 0.5) -- (2.5, 0.5);
                \draw[wire, rounded corners] (0, 1.5) -- (0.5, 1.5) -- (1.5, 0.5) -- (2.5, 0.5);
            \end{scope}
            \begin{scope}[xshift=6cm]
                \draw[wire] (0, 0) -- (1.6, 0);
                \draw[underwire, rounded corners] (0, 0.5) -- (0.5, 0.5) -- (1, 1) -- (1.6, 1);
                \draw[wire, rounded corners] (0, 0.5) -- (0.5, 0.5) -- (1, 1) -- (1.6, 1);
                \draw[wire, rounded corners] (0, 1) -- (0.5, 1) -- (1, 0.5) -- (1.6, 0.5);
                \draw[wire] (0, 1.5) -- (1.6, 1.5);
                \draw[wire] (0, 2) -- (1.6, 2);
            \end{scope}
        \end{tikzpicture}
        \ .
    \end{equation}
    We can then simplify the diagram by assuming that the wires can pass through each other and rearrange them until the diagram is more readable.
    More formally two diagrams represent the same permutation if they are equivalent up to a four-dimensional spatial isotopy, the fourth dimension allowing us to pass the wires around each other, when in three dimensions they would collide.
    This results in the following diagram:
    \begin{equation}
        \tikzsetnextfilename{math-prelims-example-diagram-simplified-composition}
        \begin{tikzpicture}[baseline=(current bounding box)]
            \draw[wire] (0, 0) -- (2, 0);
            \draw[underwire, rounded corners] (0, 0.5) -- (1, 0.5) -- (1.5, 1) -- (2, 1);
            \draw[wire, rounded corners] (0, 0.5) -- (1, 0.5) -- (1.5, 1) -- (2, 1);
            \draw[underwire, rounded corners] (0, 1) -- (0.5, 1) -- (1.5, 2) -- (2, 2);
            \draw[wire, rounded corners] (0, 1) -- (0.5, 1) -- (1.5, 2) -- (2, 2);
            \draw[underwire, rounded corners] (0, 1.5) -- (0.5, 1.5) -- (1.5, 0.5) -- (2, 0.5);
            \draw[wire, rounded corners] (0, 1.5) -- (0.5, 1.5) -- (1.5, 0.5) -- (2, 0.5);
            \draw[underwire, rounded corners] (0, 2) -- (1, 2) -- (1.5, 1.5) -- (2, 1.5);
            \draw[wire, rounded corners] (0, 2) -- (1, 2) -- (1.5, 1.5) -- (2, 1.5);
        \end{tikzpicture}
        \ .
    \end{equation}
    
    A common operation on tensors is to symmetrise or antisymmetrise over a certain set of indices \cite[50--51]{cvitanovic}.
    Denoting by \(S_{i_1\dotso i_k}\) the symmetriser over the indices \(i_1, \dotsc, i_k\) this symmetriser is given by
    \begin{equation}
        S_{i_1 \dotso i_k} \coloneqq \frac{1}{k!} \sum_{\sigma \in \symmetricGroup[k]} \sigma,
    \end{equation}
    where the permutations act on the \(k\) indices \(i_1, \dotsc, i_k\).
    This formal sum of permutations is an element of the group algebra, \(\complex[\symmetricGroup[k]]\).
    Similarly, the antisymmetriser is defined as
    \begin{equation}
        A_{i_1 \dotso i_k} \coloneqq \frac{1}{k!} \sum_{\sigma \in \symmetricGroup[k]} \sgn(\sigma) \sigma
    \end{equation}
    where \(\sgn\) is the sign function, defined to be 1 if \(\sigma\) can be written as a product of an even number of transpositions, and \(-1\) otherwise.
    
    For example, \(S_{12} = (\cycle{} + \cycle{1,2})/2\) and \(A_{12} = (\cycle{} - \cycle{1,2})/2\).
    Acting on a two index tensor, \(T^{ij}\), with these gives
    \begin{align}
        S_{12} \action T^{ij} &= T^{(ij)} = \frac{1}{2}(T^{ij} + T^{ji}),\\
        A_{12} \action T^{ij} &= T^{[ij]} = \frac{1}{2}(T^{ij} - T^{ji}).
    \end{align}
    
    In the braid notation we write a symmetriser as an empty box into which the wires being symmetrised are fed, and the antisymmetriser as a filled in box, so
    \begin{align}
        S_{12} &=
        \tikzsetnextfilename{math-prelims-2-symmetriser}
        \begin{tikzpicture}[baseline=(plus.base)]
            \draw[wire] (0, 0) -- (1.5, 0);
            \draw[wire] (0, 0.5) -- (1.5, 0.5);
            \draw[symmetriser] (0.5, -0.25) rectangle (1, 0.75);
            \node (plus) at (1, 0.25) {\phantom{+}};
        \end{tikzpicture}
        = \frac{1}{2} \bigg( \,
        \tikzsetnextfilename{math-prelims-2-symmetriser-expanded}
        \begin{tikzpicture}[baseline=(plus.base)]
            \draw[wire] (2.5, 0) -- (4, 0);
            \draw[wire] (2.5, 0.5) -- (4, 0.5);
            \node (plus) at (4.5, 0.25) {\(+\)};
            \draw[wire, rounded corners] (5, 0) -- (5.5, 0) -- (6, 0.5) -- (6.5, 0.5);
            \draw[underwire, rounded corners] (5, 0.5) -- (5.5, 0.5) -- (6, 0) -- (6.5, 0);
            \draw[wire, rounded corners] (5, 0.5) -- (5.5, 0.5) -- (6, 0) -- (6.5, 0);
        \end{tikzpicture}
        \, \bigg),\\
        A_{12} &=
        \tikzsetnextfilename{math-prelims-2-antisymmetriser}
        \begin{tikzpicture}[baseline=(plus.base)]
            \draw[wire] (0, 0) -- (1.5, 0);
            \draw[wire] (0, 0.5) -- (1.5, 0.5);
            \draw[antisymmetriser] (0.5, -0.25) rectangle (1, 0.75);
            \node (plus) at (1, 0.25) {\phantom{+}};
        \end{tikzpicture}
        = \frac{1}{2} \bigg( \,
        \tikzsetnextfilename{math-prelims-2-antisymmetriser-expanded}
        \begin{tikzpicture}[baseline=(plus.base)]
            \draw[wire] (2.5, 0) -- (4, 0);
            \draw[wire] (2.5, 0.5) -- (4, 0.5);
            \node (plus) at (4.5, 0.25) {\(-\)};
            \draw[wire, rounded corners] (5, 0) -- (5.5, 0) -- (6, 0.5) -- (6.5, 0.5);
            \draw[underwire, rounded corners] (5, 0.5) -- (5.5, 0.5) -- (6, 0) -- (6.5, 0);
            \draw[wire, rounded corners] (5, 0.5) -- (5.5, 0.5) -- (6, 0) -- (6.5, 0);
        \end{tikzpicture}
        \, \bigg).
    \end{align}
    
    \chapter{Young Tableaux}
    \section{Motivation}
    Recall our examples of tensors with symmetries from \cref{sec:overview}.
    We saw the Kronecker delta, \(\delta^{ij}\), is completely symmetric, the Levi-Civita symbol, \(\varepsilon^{ijk}\), and field strength tensor, \(F^{\mu\nu}\), are completely antisymmetric, and the Riemann tensor, \(R_{\mu\nu\rho\sigma}\), has mixed symmetry.
    In order to discus these we need a notation to quickly define the symmetries of a given tensor.
    These symmetries will all be of the form \enquote{some collection of indices} are symmetric (or antisymmetric) under exchange.
    
    % TODO: Change this section to contain more motivation
    % tesnors δ, ε, F, R have symmetry, how can we classify it? Young diagrams
    % hey, look, Young diagrams also classify partitions
    % given a Young diagram how do we construct a tensor with that symmetry? We act on a tensor with no symmetry with a Young projector
    \section{What are Young Tableaux}
    \begin{dfn}{Partition}{}
        Let \(k\) be a natural number.
        A \defineindex{partition} of \(k\) is a tuple, \(\tuple{\lambda_1, \dotsc, \lambda_n}\) such that \cite[720]{hassani}
        \begin{equation}
            k = \sum_{i = 1}^{n} \lambda_i.
        \end{equation}
        A partition is \define{ordered}\index{ordered partition} if \(\lambda_i \ge \lambda_{i+1}\) for all \(i = 1, \dotsc, n - 1\).
    \end{dfn}

    For example, \(\tuple{1,5,3}\) is a partition of 9, this is not ordered, the equivalent ordered partition is \(\tuple{5,3,1}\).
    
    \begin{dfn}{Young Diagram}{}
        Given an ordered partition \(\tuple{\lambda_1, \dotsc, \lambda_n}\) of some \(k \in \naturals\) the \defineindex{Young diagram} is formed from a row of \(\lambda_1\) boxes above a row of \(\lambda_2\) boxes and so on down to a row of \(\lambda_n\) boxes, all aligned to the left \cite[87]{cvitanovic}.
    \end{dfn}
    
    For example, the ordered partitions of four are \(\tuple{4}\), \(\tuple{3,1}\), \(\tuple{2,2}\), \(\tuple{2,1,1}\), and \(\tuple{1,1,1,1}\).
    The corresponding Young diagrams are
    \ytableausetup{smalltableaux}
    \begin{equation}
        \ydiagram{4}\,, \quad \ydiagram{3,1}\,, \quad \ydiagram{2,2}\,, \quad \ydiagram{2,1,1}\,, \qand \ydiagram{1,1,1,1}\,.
    \end{equation}
    
    \begin{dfn}{Young Tableau}{}
        Given a Young diagram we form a \defineindex{Young tableau} by writing numbers in the boxes in such a way that the numbers are increasing from left to right along a row and strictly increasing from top to bottom down a column \cite{cvitanovic}.
        A \(k\) box \defineindex{standard Young tableau} is a Young tableau using the numbers 1 through \(k\) exactly once.
    \end{dfn}
    
    For example, given the Young diagram associated with the partition \(\tuple{2,1,1}\) there are three distinct standard tableaux:
    \begin{equation}
        \ytableaushort{12,3,4}, \qquad \ytableaushort{13,2,4}, \qqand \ytableaushort{14,2,3}.
    \end{equation}
        
    \begin{dfn}{Hook Number}{}
        Given a Young diagram, \(Y\), the \defineindex{hook length} of a box is the number of boxes to the right of that box, plus the number of boxes below that box, plus 1 for the box itself.
        The \defineindex{hook number}, \(\hooknumber{Y}\), is the product of the hook lengths \cite[88]{cvitanovic}.
    \end{dfn}
    \begin{exm}{}{}
        Consider the Young diagram given by the partition \(\tuple{3,2}\):
        \begin{equation}
            Y = \ydiagram{3,2}.
        \end{equation}
        The hooks of this diagram are
        \begin{equation}
            \begin{ytableau}
                *(light highlight) \strut & *(light highlight) \strut & *(light highlight) \strut \\
                *(light highlight) \strut & \strut
            \end{ytableau}
            , \quad
            \begin{ytableau}
                \strut & *(light highlight) \strut & *(light highlight) \strut \\
                \strut & *(light highlight) \strut
            \end{ytableau}
            , \quad
            \begin{ytableau}
                \strut & \strut & *(light highlight) \strut \\
                \strut & \strut
            \end{ytableau}
            , \quad
            \begin{ytableau}
                \strut & \strut & \strut \\
                *(light highlight) \strut & *(light highlight) \strut
            \end{ytableau}
            , \qand
            \begin{ytableau}
                \strut & \strut & \strut \\
                \strut & *(light highlight) \strut
            \end{ytableau}
            .
        \end{equation}
        Labelling each box with the associated hook length gives
        \begin{equation}
            \ytableaushort{431,21}.
        \end{equation}
        The hook number is
        \begin{equation}
            \hooknumber{Y} = 4 \cdot 3 \cdot 1 \cdot 2 \cdot 1 = 24.
        \end{equation}
    \end{exm}
    
    \section{Young Projectors}
    % TODO: Add in motivating examples, such as δij, εijk, Fμν, Rμνρσ
    \begin{dfn}{Young Projector}{}
        Given a \(k\) box Young diagram, \(Y\), with \(r\) rows and \(c\) columns the \defineindex{Young projector}, \(\projector{Y}\) associated with \(Y\) is given by the following procedure \cite[91]{cvitanovic}:
        \begin{enumerate}
            \item Number the boxes \(1\) to \(k\) from left to right, top to bottom.
            \item Symmetrise over the numbers in each row.
            \item Antisymmetrise over the numbers in each column.
            \item Normalise by a factor of
            \begin{equation}
                \alpha_Y \coloneqq \frac{1}{\hooknumber{Y}} \left( \prod_{i=1}^{r} \abs{S_i}! \right) \left( \prod_{j=1}^{c} \abs{A_j}! \right).
            \end{equation}
            Here \(\hooknumber{Y}\) is the hook number of the diagram, \(\abs{S_i}\) is the length of the \(i\)th row and \(\abs{A_j}\) is the length of the \(j\)th column.
        \end{enumerate}
    \end{dfn}
    
    \begin{exm}{}{}
        Consider the \(5\) box Young tableau
        \begin{equation}
            Y = \ytableaushort{123,45}.
        \end{equation}
        Numbering the boxes we get
        \begin{equation}
            \ytableaushort{123,45}.
        \end{equation}
        We need to symmetrise over \(1\), \(2\) and \(3\), and \(4\) and \(5\), using \(S_{123}\) and \(S_{45}\), and antisymmetrise over \(1\) and \(4\), \(2\) and \(5\), and \(3\) on its own, using \(A_{14}\), \(A_{25}\), and \(A_{3} = \cycle{} = \identity\).
        
        The normalisation factor is
        \begin{align}
            \alpha_Y &= \frac{1}{24} (3!2!)(2!2!1!) = 6.
        \end{align}
        The Young projector is then
        \begin{equation}
            \projector{Y} = 6
            \tikzsetnextfilename{young-projector-example}
            \begin{tikzpicture}[baseline=(A)]
                \node (A) at (0, 0.9) {};
                \foreach \y in {0, 0.5, ..., 2} {
                    \draw[wire] (0, \y) -- ++ (0.5, 0);
                }
                \draw[wire, rounded corners] (1, 0) -- ++ (0.5, 0) -- ++ (0.5, 0.5) -- ++ (1.5, 0) -- ++ (0.5, -0.5) -- ++ (0.5, 0);
                \draw[wire, rounded corners] (1, 0.5) -- ++ (0.5, 0) -- ++ (0.5, 1) -- ++ (1.5, 0) -- ++ (0.5, -1) -- ++ (0.5, 0);
                \draw[underwire, rounded corners] (1, 1) -- ++ (0.5, 0) -- ++ (0.5, -1) -- ++ (1.5, 0) -- ++ (0.5, 1) -- ++ (0.5, 0);
                \draw[wire, rounded corners] (1, 1) -- ++ (0.5, 0) -- ++ (0.5, -1) -- ++ (1.5, 0) -- ++ (0.5, 1) -- ++ (0.5, 0);
                \draw[underwire, rounded corners] (1, 1.5) -- ++ (0.5, 0) -- ++ (0.5, -0.5) -- ++ (1.5, 0) -- ++ (0.5, 0.5) -- ++ (0.5, 0);
                \draw[wire, rounded corners] (1, 1.5) -- ++ (0.5, 0) -- ++ (0.5, -0.5) -- ++ (1.5, 0) -- ++ (0.5, 0.5) -- ++ (0.5, 0);
                \draw[wire, rounded corners] (1, 2) -- ++ (3.5, 0);
                
                \draw[symmetriser] (0.5, 2.15) rectangle (1, 0.85);
                \draw[symmetriser] (0.5, 0.65) rectangle (1, -0.15);
                \draw[antisymmetriser] (2.5, 2.15) rectangle (3, 1.35);
                \draw[antisymmetriser] (2.5, 1.15) rectangle (3, 0.35);
            \end{tikzpicture}
        \end{equation}
    \end{exm}
    
    % TODO: Citations for this section
    \section{Garnir Relations}
    The standard Young tableaux of a given shape, or rather the associated Young projectors, form a basis for the Young projectors formed from Young tableaux of that shape.
    The \defineindex{Garnir relations} give us a way of taking a projector corresponding to a nonstandard Young tableau and writing it as a sum of projectors corresponding to standard Young tableaux of the same shape.
    While the relations are on the level of the Young projectors, which are elements of the group algebra, \(\complex[\symmetricGroup]\), they are applied on the level of the Young tableaux.
    So just keep in mind that whenever we write a sum of two Young tableau the sum is actually happening one layer down in the group algebra.
    
    The Garnir relations work by taking a symmetriser, a strip of boxes in a Young tableau.
    We then apply this to the Young tableau, and there are only so many ways that this can be done without getting zero.
    We choose this symmetriser such that it involves symmetrising over indices which the projector antisymmetrises, and so the result is zero overall.
    This allows us to write a Young tableau as a sum of Young tableau which are closer to being standard Young tableau.
    
    We start with a nonstandard \(k\) box Young tableau.
    The Garnir relations are best expressed through an example.
    We'll start with the \(k = 11\) nonstandard Young tableau
    \begin{equation}
        Y = \ytableaushort{1256,38{10},47,9{11}}.
    \end{equation}
    Since a Young projector involves symmetrising over a row the order of the numbers in a row is not important, so we can always sort them in increasing order.
    The numbers in each row are already sorted in increasing order here, but if they weren't then doing so would be the first step.
    The first step to applying the Garnir relations is to identify the first space, from top left going left to right top to bottom, where the tableau fails to be standard.
    In our example this is the 8 which is above a 7.
    We then highlight from this point to the point directly below it:
    \begin{equation}
        \begin{ytableau}
            1 & 2 & 5 & 6\\
            3 & *(light highlight) 8 & *(light highlight) 10\\
            *(light highlight) 4 & *(light highlight) 7\\
            9 & 11
        \end{ytableau}
    \end{equation}
    This gives us a strip of values, \(\tuple{8,10,4,7}\).
    However, we want to think of this strip not by the numbers in the boxes but the numbers of the boxes when labelled \(1\) to \(k\):
    \begin{equation}
        \ytableaushort{1234,567,89,{10}{11}}.
    \end{equation}
    So the boxes highlighted above are \(6\), \(7\), \(8\), and \(9\).
    
    The next step is to perform all permutations of this strip which give distinct Young projectors, which means that swaps within a row are all the same.
    In this case these swaps are
    \begin{equation}
        \cycle{6,8}, \quad \cycle{6,9}, \quad \cycle{7,8}, \quad \cycle{7,9}, \qand \cycle{6,8}\cycle{7,9}.
    \end{equation}
    These permutations act on the Young tableau by permuting the values in the boxes with these numbers.
    This gives us the tableaux
    \ytableausetup{smalltableaux}
    \begin{alignat}{3}
        \cycle{6,8} \action Y &=
        \ytableaushort{1256,34{10},87,9{11}}, \qquad &
        \cycle{6,8} \action Y &=
        \ytableaushort{1256,37{10},48,9{11}}, \qquad &
        \cycle{7,8} \action Y &=
        \ytableaushort{1256,384,{10}7,9{11}}, \notag\\
        \cycle{7,9} \action Y &=
        \ytableaushort{1256,387,4{10},9{11}}, \qquad &
        \cycle{6,8}\cycle{7,9} \action Y &=
        \ytableaushort{1256,347,8{10},9{11}}.
    \end{alignat}
    We can again sort all of the rows, giving
    \begin{alignat}{3}
        \cycle{6,8} \action Y &=
        \ytableaushort{1256,34{10},78,9{11}}, \qquad &
        \cycle{6,8} \action Y &=
        \ytableaushort{1256,37{10},48,9{11}}, \qquad &
        \cycle{7,8} \action Y &=
        \ytableaushort{1256,348,7{10},9{11}}, \notag\\
        \cycle{7,9} \action Y &=
        \ytableaushort{1256,378,4{10},9{11}}, \qquad &
        \cycle{6,8}\cycle{7,9} \action Y &=
        \ytableaushort{1256,347,8{10},9{11}}.
    \end{alignat}
    The Garnir relations then tell us that
    \begin{align}
        0 &= Y + \cycle{6,8} \action Y + \cycle{6,8} \action Y + \cycle{7,8} \action Y + \cycle{7,9} \action Y + \cycle{6,8}\cycle{7,9} \action Y\\
        &= \ytableaushort{1256,38{10},47,9{11}} + \ytableaushort{1256,34{10},78,9{11}} + \ytableaushort{1256,37{10},48,9{11}} + \ytableaushort{1256,348,7{10},9{11}} + \ytableaushort{1256,378,4{10},9{11}} + \ytableaushort{1256,347,8{10},9{11}}. \notag
    \end{align}
    Thus, we can write the initial nonstandard Young tableau as
    \begin{align}
        Y &= -\cycle{6,8} \action Y - \cycle{6,8} \action Y - \cycle{7,8} \action Y - \cycle{7,9} \action Y - \cycle{6,8}\cycle{7,9} \action Y\\
        &= -\ytableaushort{1256,34{10},78,9{11}} - \ytableaushort{1256,37{10},48,9{11}} - \ytableaushort{1256,348,7{10},9{11}} - \ytableaushort{1256,378,4{10},9{11}} - \ytableaushort{1256,347,8{10},9{11}}.
    \end{align}
    
    At this point there are two possibilities, if all of the Young tableaux appearing on the right are standard, as is the case here, then we are finished.
    If one or more is not standard then the first point at which it fails to be standard will have moved right and/or down, meaning it is, in a sense, closer to being standard.
    We can then apply the Garnir relations to this tableau and the failure point will once again move right and/or down.
    Since tableau are finite eventually this process must terminate and we will be left with only standard tableau.
    
    To summarise, the process of writing a nonstandard tableau in terms of standard tableau is as follows:
    \begin{enumerate}
        \item Sort the rows of the tableau into ascending order, if the result is a standard tableau stop here.
        \item Identify the first point from the top left going left to right and top to bottom where the tableau fails to be standard.
        \item Identify a strip going from this point to the box under this point.
        \item Apply all permutations to this strip which result in distinct tableau.
        \item The original tableau is then the negative of the sum of these permuted tableau.
        \item If any of the tableau in this sum are nonstandard recursively apply the Garnir relations.
        When no nonstandard tableau remain stop.
    \end{enumerate}
    Another example, where the Garnir relations are applied recursively, is in \cref{app:garnir example}
    
    \section{Irreducible Representations of The Symmetric Group}
    \subsection{Irreducible Representations of \texorpdfstring{\(\symmetricGroup\)}{Sn} Labelled by Young Diagrams}
    Given a group, \(G\), we can define an equivalence relation, \(\sim\), where \(g \sim g'\) if and only if there exists some \(h \in G\) such that \(g = hg'g^{-1}\).
    If this is the case we say that \(g\) and \(g'\) are conjugates.
    We can then take the equivalence classes, in this context called \defineindex{conjugacy classes}, and these partition \(G\).
    
    Consider the particular case when \(G = \symmetricGroup\) is the symmetric group.
    Any permutation can be written as a product of disjoint cycles, that is cycles where no number appears in more than one cycle \cite{conjugacy-classes-cycle-types}.
    We can further order the cycles in decreasing order, and add in any element not appearing in a cycle in a singleton cycle, \(\cycle{k}\), which is just the identity, \(\cycle{}\).
    This standard form is unique up to order of the cycles in the product and cyclic permutations of the elements within any given cycle.
    We can then define the \defineindex{cycle type} of this permutation to be the lengths of the cycles when written in this standard form.
    For example, the permutation \(\sigma = \cycle{1,2}\cycle{3,5} \in \symmetricGroup[5]\) has standard form \(\cycle{1,2}\cycle{3,5}\cycle{4}\), which has cycle type \(\tuple{2,2,1}\).
    Since every number from 1 to \(n\) appears in exactly one cycle the cycle type is a partition of \(n\).
    It can then be shown that two permutations are conjugate if and only if they have the same cycle type \cite{conjugacy-classes-cycle-types}.
    
    Fix some representation, \(\rho \colon G \to \generalLinear(V)\) for a finite dimensional vector space \(V\) over a field \(\field\).
    The \defineindex{character} of \(\rho\) is the map \(\chi_\rho\colon G \to \field\) given by \(\chi_\rho(g) = \tr(\rho(g))\).
    It is a basic result of character theory that given a conjugacy class, \([g]\), all elements of this conjugacy class have the same character, \(\chi_\rho(g)\), in a fixed representation
    This follows directly from the cyclic property of the trace and the fact that \(\rho\) is a group homomorphism.
    
    The character table of a group has columns labelled by conjugacy classes, and rows labelled by irreducible representations of the group.
    The entries into the table are then the characters associated with the conjugacy class labelling the column in the representation labelling the row.
    It can be shown that the character table is always a square \cite{zhenheng}.
    That is, there are as many irreducible representations as there are conjugacy classes.
    
    The culmination of these definitions and observations is that there is one irreducible representation of \(\symmetricGroup\) for every conjugacy class, one conjugacy class for every cycle type, one cycle type for every partition of \(n\), and one partition of \(n\) for every \(n\) box Young diagram.
    Hence there is a one-to-one correspondence between irreducible representations of \(\symmetricGroup\) and \(n\) box Young diagrams.
    
    \subsection{Elements of \texorpdfstring{\(\symmetricGroup\)}{Sn} Labelled by Young Tableaux}
    Consider \(\symmetricGroup\) and fix some \(n\) box Young diagram, \(Y\).
    The identity permutation can be represented by the Young tableau of shape \(Y\) with the numbers 1 through \(n\) entered in order from left to right, top to bottom.
    For example, if we consider \(\symmetricGroup[5]\) and the Young diagram
    \begin{equation}
        Y = \ydiagram{3,2}
    \end{equation}
    then the identity permutation, \(\cycle{}\), is represented by
    \begin{equation}
        Y_{\cycle{}} = \ytableaushort{123,45}.
    \end{equation}
    
    Another permutation, \(\sigma \in \symmetricGroup\), can then act on this Young tableau by permuting the numbers in the boxes.
    For example, \(\cycle{1,2}\cycle{3,4}\) acts on the ordered Young tableaux \(Y_{\cycle{}}\) to give
    \begin{equation}
        Y_{\cycle{1,2}\cycle{3,4}} = \cycle{1,2}\cycle{3,4}\action \ytableaushort{123,45} = 
        \ytableaushort{214,35}.
    \end{equation}
    This action defines a bijection between \(\symmetricGroup\) and the set of all Young tableaux of shape \(Y\).
    Thus, there is a one-to-one correspondence between permutations and Young tableaux of a fixed shape, so we can label permutations with Young tableau of a fixed shape.
    The obvious shape to choose is the shape corresponding to the diagram labelling the representation we are interested in working in.
    
    \subsection{Dimension of the Representation}
    Let \(Y\) be an \(n\) box Young diagram labelling the irreducible representation \(\rho_Y\colon \symmetricGroup \to \generalLinear(V_Y)\) of the symmetric group \(\symmetricGroup\).
    It is possible to show that the dimension of \(V_Y\) is equal to the number of standard Young tableaux of shape \(Y\).
    This number can in turn be computed using the \defineindex{hook formula}, which tells us that the number of standard tableaux of shape \(Y\), \(d_Y\), is given by
    \begin{equation}
        d_Y = \frac{n!}{\hooknumber{Y}} = \dim V_Y.
    \end{equation}
    
    % TODO: Put a citation for a proof of the hook formula, or multiple proofs since there are many ways to prove it?
    For example, the Young diagram
    \begin{equation}
        Y = \ydiagram{3,2}
    \end{equation}
    has the following five standard tableaux:
    \begin{equation}
        \ytableaushort{123,45}, \qquad \ytableaushort{124,35}, \qquad \ytableaushort{125,34}, \qquad \ytableaushort{134,25}, \qqand \ytableaushort{135,24}.
    \end{equation}
    The hook number, \(\hooknumber{Y}\), is \(4 \cdot 3 \cdot 2 = 24\).
    Thus the hook formula predicts that there are
    \begin{equation}
        d_Y = \frac{5!}{24} = 5
    \end{equation}
    standard tableaux of this shape, which agrees with what we've written down.
    
    What this tells us is that there is a one-to-one correspondence between standard Young tableau of a given shape and a basis for the representation space associated with that shape.
    We will make use of this in the next section when it comes to actually computing the representations of \(\symmetricGroup\).
    
    These relations between Young diagrams and tableaux and the representation theory of the symmetric group are summarised in \cref{fig:one-to-one relations in Sn}.
    
    \begin{figure}
        \tikzexternaldisable
        \begin{tabular}{c}
            \begin{tikzcd}
                & \text{conjugacy classes of \(S_n\)} \arrow[r, <->] & \text{cycle types} \arrow[dd, <->] \\
                \text{irreps of \(\symmetricGroup\)} \arrow[ur, <->] \arrow[dr, <->] && \\
                & \text{\(n\) box Young diamgrams} \arrow[r, <->] & \text{partitions of \(n\)}
            \end{tikzcd}
            \\[10ex]
            \begin{tikzcd}
                \text{elements of \(\symmetricGroup\)} \arrow[r, <->] & \text{\(n\) box Young tableau of a given shape}
            \end{tikzcd}
            \\[2ex]
            \begin{tikzcd}
                \text{standard tableaux of shape \(Y\)} \arrow[r, <->] & \text{basis vectors of \(V_Y\)}
            \end{tikzcd}
        \end{tabular}
        \tikzexternalenable
        \caption{One-to-one relations between various concepts relating to Young diagrams and tableaux, and representations of \(S_n\).}
        \label{fig:one-to-one relations in Sn}
    \end{figure}
    
    
    \subsection{Computing Representations of \texorpdfstring{\(\symmetricGroup\)}{Sn}}
    The question now is given some \(\sigma \in \symmetricGroup\) and some \(n\) box Young diagram, \(Y\), how do we find the matrix corresponding to \(\sigma\) in the representation labelled by \(Y\)\kern0.1em?
    We'll follow demonstrate the procedure with the example \(\sigma = \cycle{1,3}\) and the representation labelled by the Young diagram
    \begin{equation}
        Y = \ydiagram{2,1}.
    \end{equation}
    Start by identifying this Young diagram with the ordered Young tableau of the same shape:
    \begin{equation}
        Y_{\cycle{}} = \ytableaushort{12,3}.
    \end{equation}
    
    The dimension of the representation is given by the number of standard tableaux of the same shape as \(Y\).
    The hook formula gives the dimension
    \begin{equation}
        d_Y = \frac{3!}{3} = 2,
    \end{equation}
    and indeed there are two standard Young tableaux of this shape:
    \begin{equation}
        \ytableaushort{12,3}, \qqand \ytableaushort{13,2}.
    \end{equation}
    From each of these standard tableaux we can identify a \defineindex{standard permutation}, the permutation which acts on \(Y_{\cycle{}}\) to give the standard tableau, in this case the standard permutations are \(\cycle{}\) and \(\cycle{2,3}\).
    
    We need the Young projector associated with \(Y\):
    \begin{equation}
        \projector{Y} = \frac{4}{3} \,
        \tikzsetnextfilename{rep-of-Sn-example-Young-projector}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire] (0, 1) -- (0.5, 1);
            \draw[wire] (0, 0.5) -- (0.5, 0.5);
            \draw[wire] (1, 1) -- (2.5, 1);
            \draw[wire] (3, 1) -- (4.5, 1);
            \draw[wire, rounded corners] (0, 0) -- (1.5, 0) --  (2, 0.5) -- (2.5, 0.5);
            \draw[wire, rounded corners] (3, 0.5) -- (3.5, 0.5) -- (4, 0) -- (4.5, 0);
            \draw[underwire, rounded corners] (1, 0.5) -- (1.5, 0.5) -- (2, 0) -- (3.5, 0) -- (4, 0.5) -- (4.5, 0.5);
            \draw[wire, rounded corners] (1, 0.5) -- (1.5, 0.5) -- (2, 0) -- (3.5, 0) -- (4, 0.5) -- (4.5, 0.5);
            \draw[symmetriser] (0.5, 0.25) rectangle (1, 1.25);
            \draw[antisymmetriser] (2.5, 0.25) rectangle (3, 1.25);
        \end{tikzpicture}
        =
        \tikzsetnextfilename{rep-ofSn-example-Young-projector-short-form}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire] (0, 1) -- (0.5, 1);
            \draw[wire] (0, 0.5) -- (0.5, 0.5);
            \draw[wire] (0, 0) -- (0.5, 0);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{12,3}};
        \end{tikzpicture}
        .
    \end{equation}
    If we act on the left of this projector with our two standard permutations we get
    \begin{equation}
        \cycle{} \action \projector{Y} = \projector{Y} = \ve{1}, \qqand \cycle{2,3} \action \projector{Y} = 
        \tikzsetnextfilename{rep-of-Sn-second-basis-element}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire] (-0.5, 1) -- (0, 1) -- (0.5, 1);
            \draw[wire, rounded corners] (-0.5, 0) -- (-0.25, 0) -- (0.25, 0.5) -- (0.5, 0.5);
            \draw[underwire, rounded corners] (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[wire, rounded corners] (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{12,3}};
        \end{tikzpicture}
        = \ve{2}.
    \end{equation}
    We take these two projectors to form a basis, \(\{\ve{1}, \ve{2}\}\), for our representation space.
    Next act on this basis with \(\sigma = \cycle{1,3}\), giving
    \begin{align}
        \cycle{1,3} \action \ve{1} &=
        \tikzsetnextfilename{rep-of-Sn-step-1}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire, rounded corners] (-0.5, 1) -- (-0.25, 1) -- (0.25, 0) -- (0.5, 0);
            \draw[underwire] (-0.5, 0.5) -- (0.5, 0.5);
            \draw[wire] (-0.5, 0.5) -- (0.5, 0.5);
            \draw[underwire, rounded corners] (-0.5, 0) -- (-0.25, 0) -- (0.25, 1) -- (0.5, 1);
            \draw[wire, rounded corners] (-0.5, 0) -- (-0.25, 0) -- (0.25, 1) -- (0.5, 1);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{12,3}};
        \end{tikzpicture}
        =
        \tikzsetnextfilename{rep-of-Sn-step-2}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire] (0, 1) -- (0.5, 1);
            \draw[wire] (0, 0.5) -- (0.5, 0.5);
            \draw[wire] (0, 0) -- (0.5, 0);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{32,1}};
        \end{tikzpicture}
        =
        \tikzsetnextfilename{rep-of-Sn-step-3}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire] (0, 1) -- (0.5, 1);
            \draw[wire] (0, 0.5) -- (0.5, 0.5);
            \draw[wire] (0, 0) -- (0.5, 0);
            \draw[wire] (2.5, 1) -- (3, 1);
            \draw[wire] (2.5, 0.5) -- (3, 0.5);
            \draw[wire] (2.5, 0) -- (3, 0);
            \draw (0.5, -0.25) rectangle (2.5, 1.25);
            \node at (1.5, 0.5) {-\,\ytableaushort{12,3} \, - \ytableaushort{13,2}};
        \end{tikzpicture}
        \notag\\
        &= -
        \tikzsetnextfilename{rep-of-Sn-step-4}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire] (0, 1) -- (0.5, 1);
            \draw[wire] (0, 0.5) -- (0.5, 0.5);
            \draw[wire] (0, 0) -- (0.5, 0);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{12,3}};
        \end{tikzpicture}
        -
        \tikzsetnextfilename{rep-of-Sn-step-5}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire] (-0.5, 1) -- (0, 1) -- (0.5, 1);
            \draw[wire, rounded corners] (-0.5, 0) -- (-0.25, 0) -- (0.25, 0.5) -- (0.5, 0.5);
            \draw[underwire, rounded corners] (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[wire, rounded corners] (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{12,3}};
        \end{tikzpicture}
        = -\ve{1} - \ve{2}.
    \end{align}
    Here we have acted on the inputs to the Young projector.
    Then interpreted this as acting by permutations on the underlying Young tableau.
    We then decomposed the permuted Young tableau into a sum of standard tableaux using the Garnir relations.
    Finally we take this linear combination of standard tableaux and replace each standard tableaux with the corresponding standard permutation acting on the ordered tableau.
    Thus we are left with a linear combination of standard permutations acting on the Young projector associated with the Young diagram \(Y\).
    We then interpret this as a sum of basis vectors in the representation space.
    
    We can do exactly the same with the second basis vector to get
    \begin{align}
        \cycle{1,3} \action \ve{2} &= 
        \tikzsetnextfilename{rep-of-Sn-step-6}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire, rounded corners] (-1.5, 1) -- (-1.25, 1) -- (-0.75, 0) -- (-0.5, 0) -- (-0.25, 0) -- (0.25, 0.5) -- (0.5, 0.5);
            \draw[underwire, rounded corners] (-1.5, 0.5) -- (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[wire, rounded corners] (-1.5, 0.5) -- (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[underwire, rounded corners] (-1.5, 0) -- (-1.25, 0) -- (-0.75, 1) -- (0.5, 1);
            \draw[wire, rounded corners] (-1.5, 0) -- (-1.25, 0) -- (-0.75, 1) -- (0.5, 1);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{12,3}};
        \end{tikzpicture}
        =
        \tikzsetnextfilename{rep-of-Sn-step-7}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire, rounded corners] (-0.5, 0) -- (-0.25, 0) -- (0.25, 1) -- (0.5, 1);
            \draw[underwire, rounded corners] (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[underwire, rounded corners] (-0.5, 1) -- (-0.25, 1) -- (0.25, 0.5) -- (0.5, 0.5);
            \draw[wire, rounded corners] (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[wire, rounded corners] (-0.5, 1) -- (-0.25, 1) -- (0.25, 0.5) -- (0.5, 0.5);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{12,3}};
        \end{tikzpicture}
        \\
        &=
        \tikzsetnextfilename{rep-of-Sn-step-8}
        \begin{tikzpicture}[baseline=0.42cm]
            \draw[wire] (-0.5, 1) -- (0, 1) -- (0.5, 1);
            \draw[wire, rounded corners] (-0.5, 0) -- (-0.25, 0) -- (0.25, 0.5) -- (0.5, 0.5);
            \draw[underwire, rounded corners] (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[wire, rounded corners] (-0.5, 0.5) -- (-0.25, 0.5) -- (0.25, 0) -- (0.5, 0);
            \draw[wire] (1.5, 1) -- (2, 1);
            \draw[wire] (1.5, 0.5) -- (2, 0.5);
            \draw[wire] (1.5, 0) -- (2, 0);
            \draw (0.5, -0.25) rectangle (1.5, 1.25);
            \node at (1, 0.5) {\ytableaushort{12,3}};
        \end{tikzpicture}
        = \ve{2}.
    \end{align}
    In the last step we identified that the projector is symmetric in the first two inputs, since these are symmetrised over.
    So, we are free to swap the first two input wires, which leaves us with a permutation acting on the Young projector \(\projector{Y}\), which we identify as \(\ve{2}\).
    If we hadn't seen that this was possible then we could have applied the permutation to the Young tableau as we did for the first term, and then decomposed the result with the Garnir relations, and the answer would be the same, it's just slower.
    
    Now we have seen how this permutation, \(\cycle{1,3}\), acts on the basis vectors, \(\{\ve{1}, \ve{2}\}\), we can extend this by linearity to the whole representation space.
    We can then write this action as a matrix equation and read off the entries of the matrix.
    The one subtlety is that we placed the permutations on the left of the Young projector, but this corresponds to multiplying on the right by the permutation, so we act on the right with the matrix.
    Thus, we can find the representation of \(\cycle{1,3}\):
    \begin{equation}
        \begin{pmatrix}
            \ve{1} & \ve{2}
        \end{pmatrix}
        \rho\cycle{1,3} = 
        \begin{pmatrix}
            -\ve{1} - \ve{2} & \ve{2}
        \end{pmatrix}
        \implies \rho\cycle{1,3} = 
        \begin{pmatrix}
            -1 & 0\\
            -1 & 1
        \end{pmatrix}
        .
    \end{equation}

    To summarise the process given some \(\sigma \in \symmetricGroup\) and an \(n\) box Young diagram labelling a representation we can find the action of \(\sigma\) in this representation as follows:
    \begin{enumerate}
        \item Write down the \(d_Y = n!/\hooknumber{Y}\) standard tableaux of the same shape, these give the standard permutations, \(\tau_i\).
        \item Act on the Young projector, \(\projector{Y}\), with the standard permutations to get the basis elements, \(\ve{i} = \tau_i \action \projector{Y}\).
        \item Act on each basis element with the permutation, \(\sigma \action \ve{i}\).
        \item Simplify the result using Garnir relations until the result is written in terms of \(\ve{i}\).
        \item Solve the equation
        \begin{equation}
            \begin{pmatrix}
                \ve{1} & \cdots & \ve{d}
            \end{pmatrix}
            \rho(\sigma) = 
            \begin{pmatrix}
                \sigma \action \ve{1} & \cdots & \sigma \action \ve{d}
            \end{pmatrix}
        \end{equation}
        for the \(d \times d\) representation matrix, \(\rho(\sigma)\).
    \end{enumerate}
    
    Notice that at no point in this process did we ever actually have to use the Young projector, it is enough to know the symmetries which it possesses, which is fully determined by the shape of the Young diagram \(Y\).
    We then exploit these symmetries in the step where we apply the Garnir relations.
    
    \section{Hermitian Young Projectors}
    For Young diagrams with three or more boxes the associated Young projectors are not, in general, Hermitian.
    Hermiticity is often a desirable property.
    Fortunately it is possible to construct Hermitian Young projectors from the Young projectors we already have.
    
    \begin{dfn}{Hermitian Young Projectors}{}
        Denote by \(Y_{\Theta}\) the standard Young projector associated with the Young tableaux \(\Theta\).
        Let \(\Theta\) be the Young tableaux we get by removing the box with the highest number.
        Construct the following
        \begin{equation}
            P_{\Theta} \coloneqq
            \begin{cases}
                Y_{\Theta} & \text{if } \Theta \text{ is has 2 or fewer boxes},\\
                (P_{\Theta'} \otimes 1) Y_{\Theta} (P_{\Theta'} \otimes 1) & \text{if } \Theta \text{ has 3 or more boxes}.
            \end{cases}
        \end{equation}
    \end{dfn}
    
    That \(P_{\Theta}\) are Hermitian is proven in \cite{keppeler-hermitian-young-projectors}.
    
    The construction of \(P_{\Theta}\) is clearer in the diagrammatic notation, where the recursive definition is
    \begin{equation}
        \tikzsetnextfilename{hermitian-young-projector}
        \begin{tikzpicture}[baseline=(equal.base), font=\scriptsize]
            \draw (0, -0.25) rectangle (1, 1.75) node [midway] (Ptheta) {\(P_{\Theta}\)};
            \draw[wire] (-0.5, 0) -- (0, 0);
            \draw[wire] (-0.5, 0.5) -- (0, 0.5);
            \draw[wire] (-0.5, 1.5) -- (0, 1.5);
            \node at (-0.25, 1) {\(\vdots\)};
            \draw[wire] (1, 0) -- (1.5, 0);
            \draw[wire] (1, 0.5) -- (1.5, 0.5);
            \draw[wire] (1, 1.5) -- (1.5, 1.5);
            \node at (1.25, 1) {\(\vdots\)};
            \node[right=of Ptheta] (equal) {\(=\)};
            \draw (3, 0.25) rectangle (4, 1.75) node [midway] {\(P_{\Theta'}\)};
            \draw[wire] (2.5, 0) -- (4.5, 0);
            \draw[wire] (2.5, 0.5) -- (3, 0.5);
            \draw[wire] (2.5, 1.5) -- (3, 1.5);
            \node at (2.75, 1) {\(\vdots\)};
            \draw[wire] (4, 0.5) -- (4.5, 0.5);
            \draw[wire] (4, 1.5) -- (4.5, 1.5);
            \node at (4.25, 1) {\(\vdots\)};
            \draw (4.5, -0.25) rectangle (5.5, 1.75) node [midway] {\(Y_{\Theta}\)};
            \draw[wire] (5.5, 0) -- (7.5, 0);
            \draw[wire] (5.5, 0.5) -- (6, 0.5);
            \draw[wire] (5.5, 1.5) -- (6, 1.5);
            \node at (5.75, 1) {\(\vdots\)};
            \draw (6, 0.25) rectangle (7, 1.75) node [midway] {\(P_{\Theta'}\)};
            \draw[wire] (7, 0.5) -- (7.5, 0.5);
            \draw[wire] (7, 1.5) -- (7.5, 1.5);
            \node at (7.25, 1) {\(\vdots\)};
        \end{tikzpicture}
        .
    \end{equation}
    Hermiticity in the diagrammatic notation corresponds to a vertical mirror symmetry, which is clearly present here.
    
    
    % TODO: Example of Hermitian Young projector construction
    
    % TODO: Talk about difference between Young projectors as related to Sn and SU(N) irreps
    % TODO: Talk about 3j and 6js and how every diagram can be reduced to them
    
    \printbibliography
    % Appdendix
    \appendixpage
    \begin{appendices}
        \chapter{Linear Algebra}\label{sec:linear algebra}
        We assume the reader is familiar with basic linear algebra, specifically working with vectors and matrices.
        We will make use of certain concepts, such as direct sums and dual spaces, which are less common in physics, so we shall define them here.
        
        \section{Vector Spaces}
        Recall that a \defineindex{vector space} is a set, \(V\), along with a field of scalars, \(\field\), equipped with the operations of vector addition \(+ \colon V \times V \to V\), and scalar multiplication, \(\field \times V \to V\), such that
        \begin{itemize}
            \item \((V, +)\) is an Abelian group,
            \item scalar multiplication distributes over vector addition: \(z(v + u) = zv + zv\) for all \(z \in \field\) and \(u, v \in V\),
            \item scalar multiplication distributes over field addition: \((z + w)v = zv + wv\) for all \(z, w \in \field\) and \(v \in V\),
            \item \(1v = v\) for all \(v \in V\) where \(1 \in \field\) is the multiplicative identity,
            \item scalar multiplication and field multiplication are compatible, \(z(wv) = (zw)v\) for all \(z, w \in \field\) and \(v \in V\).
        \end{itemize}
        
        Given vector spaces \(V\) and \(W\) over the field \(\field\) a \defineindex{linear map} is a function \(\varphi \colon V \to W\) such that
        \begin{equation}
            \varphi(zv + u) = z\varphi(v) + \varphi(u)
        \end{equation}
        for all \(z\in \field\) and \(v, u \in V\).
        
        Given a vector space, \(V\), over the field \(\field\) we can form another vector space, \(\dual{V}\), also over \(\field\) called the \defineindex{dual space}, whose elements are linear maps \(V \to \field\), where \(\field\) is viewed as a one dimensional vector space over itself.
        Vector addition in \(\dual{V}\) is defined pointwise, so given linear maps \(\varphi, \psi \in \dual{V}\) their sum is the linear map \(\varphi + \psi \in \dual{V}\) defined by \((\varphi + \psi)(v) = \varphi(v) + \psi(v)\).
        Similarly, scalar multiplication in \(\dual{V}\) is defined such that given \(z \varphi \in \dual{V}\) and \(z \in \field\) we have \(z\varphi \in \dual{V}\) defined by \((z\varphi)(v) = z[\varphi(v)]\).
        
        \section{Tensor Products}
        Given two vector spaces \(V\) and \(W\) over \(\field\) we can form a new vector space, also over \(\field\), called their \defineindex{tensor product}, \(V \otimes W\).
        The simplest definition of the tensor product is basis dependent.
        Given bases \(\{e_i\}\) and \(\{d_j\}\) for \(V\) and \(W\) respectively \(V \otimes W\) is the span, that is all linear combinations, of \(\{e_i \otimes d_j\}\), where \(e_i \otimes d_j\) is the tensor product of the basis vectors \(e_i\) and \(d_j\).
        Notice that \(\dim(V \otimes W) = \dim(V) \dim(W)\).
        
        An arbitrary vector \(x \in V \otimes W\), then takes the form
        \begin{equation}
            x^{ij}e_i \otimes d_j,
        \end{equation}
        with the summation convention in effect.
        The components of this vector are the numbers \(x^{ij}\).
        
        The tensor product of \(v = v^ie_i \in V\) and \(w = w^jd_j \in W\) their tensor product is the vector \(v \otimes w = v^id^j e_i \otimes d_j\).
        That is, the vector with components \(v^iw^j\).
        So in index notation the tensor product is simply given by putting the vectors, or more generally tensors, next to each other with distinct indices.
        
        \section{Direct Sum}
        Given two vector spaces \(V\) and \(W\) over \(\field\) we can form a new vector space, also over \(\field\), called their \defineindex{direct sum}, \(V \oplus W\).
        The vectors here are the elements of the Cartesian product \(V \times W\), so take the form \((v, w)\) with \(v \in V\) and \(w \in W\).
        Vector addition is defined by \((v, w) + (v', w') = (v + v', w + w')\) for \(v, v' \in V\) and \(w, w' \in W\).
        Scalar addition is defined by \(z(v, w) = (zv, zw)\) for \(z \in \field\), \(v \in V\) and \(w \in W\).
        Notice that \(\dim(V \oplus W) = \dim(V) + \dim(W)\).
        
        Given a vector space \(V\) with subspace \(W\) we can identify a second subspace \(W^{\perp}\) which is such that \(V = W \oplus W^{\perp}\).
        
        
        \chapter{Technicalities}
        There are many technicalities which are worth mentioning but would detract from the body of the report.
        These have been relegated to this appendix.
        
        \section{Multiple Definitions of Tensors}\label{sec:technicalities tensor defs}
        There are multiple, slightly different, definitions of tensors used across various fields of mathematics and science.
        A computer scientist might define a tensor to be a multi-dimensional array, so a rank 0 tensor is a number, a rank 1 tensor is a list, a rank 2 tensor is a matrix, and so on.
        This is fine, so long as we are only interested in working in one basis.
        
        The physics definition of a tensor, the one which we shall introduce shortly, does indeed take a tensor to be a collection of numbers, \(\tensor{T}{^{a_1\dotso a_q}_{b_1\dotso b_p}}\), but these numbers must also must follow a transformation law for how these numbers change under a transformation.
        Exactly what this law is depends on what sort of transformations we consider, and so this leads to the famously unhelpful \enquote{a tensor is something which transforms like a tensor}.
        
        A mathematician would define a tensor in one of two ways.
        To do so they start with a vector space, \(V\), over some field, \(\field\), then define the dual space, \(V^*\), which is the vector space formed from all linear functions \(V \to \field\), with addition and scalar multiplication defined pointwise.
        So, given \(\varphi, \psi \in V\) and \(z \in \field\) we have \((\varphi + \psi)(v) = \varphi(v) + \psi(v)\) and \((z\varphi)(v) = z[\varphi(v)]\) for all \(v \in V\).
        
        The first mathematician definition is then as follows.
        A tensor is a multilinear mapping \(T \colon V\ \times \dotsm V \times V^* \times \dotsb \times V^* \to \field\), where we have \(p\) copies of \(V\) and \(q\) copies of \(V^*\).
        In this case the physicists definition is that \(\tensor{T}{^{a_1 \dotso a_q}_{b_1 \dotso b_p}}\) corresponds to a tensor field, a function assigning a tensor to every point in spacetime in a basis independent way, evaluated on some set of basis vectors \(\{\ve{i}\}\) and dual basis covectors \(\{\dualve{j}\}\), so that
        \begin{equation}
            \tensor{T}{^{a_1 \dotso a_q}_{b_1 \dotso b_p}} = T(\ve{a_1}, \dotsc, \ve{a_q}, \dualve{b_1}, \dotsc, \dualve{b_p})
        \end{equation}
        
        Alternatively, a mathematician may first define the tensor product \(V \otimes W\), of two vector spaces, \(V\) and \(W\).
        Then a tensor is simply a vector in such a vector space.
        In particular one can identify the multilinear map definition above with a vector \(T \in V \otimes \dotsb \otimes V \otimes V^* \otimes \dotsm V^*\), again with \(p\) copies of \(V\) and \(q^*\) copies of \(V^*\).
        Then the physicists definition of a tensor are simply the components of this vector.
        This is the same definition we give in \cref{def:tensor}, although we then immediately switch to discussing the components.
        
        The relation between the two mathematician's definitions is due to the tensor-hom adjunction which says that there a canonical bijective mapping between tensor products and linear maps.
        
        \chapter{Garnir Relations Example}\label{app:garnir example}
        \section{Recursive Application}
        Consider the Young tableau
        \begin{equation}
            Y = \ytableaushort{14,35,2}.
        \end{equation}
        The rows are already sorted.
        The problem strip starts with the 3:
        \begin{equation}
            \begin{ytableau}
                1 & 4\\
                *(light highlight) 3 & *(light highlight) 5\\
                *(light highlight) 2
            \end{ytableau}
        \end{equation}
        The box numbers are
        \begin{equation}
            \ytableaushort{12,34,5},
        \end{equation}
        so the boxes in the strip are numbers 3, 4, and 5.
        We need to consider the permutations \(\cycle{3,5}\) and \(\cycle{4,5}\), giving
        \begin{equation}
            \cycle{3,5} \action Y = \ytableaushort{14,25,3}, \qqand \cycle{4,5} \action Y = \ytableaushort{14,32,5}.
        \end{equation}
        Sorting the rows we get the tableaux
        \begin{equation}
            \ytableaushort{14,25,3}, \qqand \ytableaushort{14,23,5}.
        \end{equation}
        Thus
        \begin{equation}
            Y = \ytableaushort{14,35,2} = -\ytableaushort{14,25,3} - \ytableaushort{14,23,5}.
        \end{equation}
        The first tableau is standard, but the second isn't, we have a four above a 3.
        So, we need to recursively apply the Garnir relations.
        
        Starting again with
        \begin{equation}
            \tilde{Y} = \ytableaushort{14,23,5}
        \end{equation}
        we identify the problem strip:
        \begin{equation}
            \begin{ytableau}
                1 & *(light highlight) 4\\
                *(light highlight) 2 & *(light highlight) 3\\
                5
            \end{ytableau}
        \end{equation}
        Notice that the problem point has moved right compared to the starting tableau \(Y\).
        We need to consider the permutations \(\cycle{2,3}\) and \(\cycle{2,4}\).
        Applying these gives
        \begin{equation}
            \cycle{2,3} \action \tilde{Y} = \ytableaushort{12,43,5}, \qqand \cycle{2,4} \action \tilde{Y} = \ytableaushort{13,24,5}.
        \end{equation}
        Sorting the rows gives
        \begin{equation}
            \ytableaushort{12,34,5}, \qqand \ytableaushort{13,24,5}.
        \end{equation}
        Hence, we have
        \begin{equation}
            \tilde{Y} = -\ytableaushort{12,34,5} - \ytableaushort{13,24,5}.
        \end{equation}
        
        Going back to our original tableau we can express \(Y\) as a sum of standard tableaux:
        \begin{align}
            Y &= - \ytableaushort{14,25,3} - \ytableaushort{14,23,5}\\
            &= -\ytableaushort{14,25,3} - \left( -\ytableaushort{12,34,5} - \ytableaushort{13,24,5} \, \right)\\
            &= -\ytableaushort{14,25,3} + \ytableaushort{12,34,5} + \ytableaushort{13,24,5}.
        \end{align}
        Notice that since the Young projectors, denoted here by the corresponding Young tableaux, are elements of an algebra, \(\complex[\symmetricGroup[5]]\), we can do all of the expected algebra with them such as distributing scalars over sums since \(\complex[\symmetricGroup[5]]\) is a vector space.
    \end{appendices}
    
    \backmatter
    %    \renewcommand{\glossaryname}{Acronyms}
    %    \printglossary[acronym]
    \printindex
\end{document}